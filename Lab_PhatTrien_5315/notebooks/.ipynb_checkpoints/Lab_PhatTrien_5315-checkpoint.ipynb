{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c12093",
   "metadata": {},
   "source": [
    "## 1. L√Ω thuy·∫øt v·ªÅ High-Utility Itemset Mining\n",
    "\n",
    "### 1.1 Kh√°i ni·ªám c∆° b·∫£n\n",
    "\n",
    "**Utility** (gi√° tr·ªã/l·ª£i √≠ch) c·ªßa m·ªôt itemset trong m·ªôt giao d·ªãch ƒë∆∞·ª£c t√≠nh b·∫±ng:\n",
    "\n",
    "$$U(X, T_k) = \\sum_{x \\in X} q(x, T_k) \\times p(x)$$\n",
    "\n",
    "Trong ƒë√≥:\n",
    "- $X$: Itemset (t·∫≠p c√°c s·∫£n ph·∫©m)\n",
    "- $T_k$: Giao d·ªãch th·ª© k\n",
    "- $q(x, T_k)$: S·ªë l∆∞·ª£ng c·ªßa item x trong giao d·ªãch $T_k$ (internal utility)\n",
    "- $p(x)$: L·ª£i nhu·∫≠n/gi√° c·ªßa item x (external utility)\n",
    "\n",
    "**T·ªïng Utility** c·ªßa itemset X trong to√†n b·ªô database:\n",
    "\n",
    "$$U(X) = \\sum_{T_k \\supseteq X} U(X, T_k)$$\n",
    "\n",
    "### 1.2 V·∫•n ƒë·ªÅ v·ªõi Downward Closure Property\n",
    "\n",
    "Trong Frequent Pattern Mining, t√≠nh ch·∫•t **Apriori** (downward closure) cho ph√©p c·∫Øt t·ªâa hi·ªáu qu·∫£:\n",
    "- N·∫øu itemset X kh√¥ng ph·ªï bi·∫øn ‚Üí t·∫•t c·∫£ superset c·ªßa X c≈©ng kh√¥ng ph·ªï bi·∫øn\n",
    "\n",
    "**Nh∆∞ng v·ªõi Utility**, t√≠nh ch·∫•t n√†y **KH√îNG** c√≤n ƒë√∫ng:\n",
    "- {A} c√≥ utility = 10\n",
    "- {A, B} c√≥ th·ªÉ c√≥ utility = 100 (do B c√≥ gi√° tr·ªã cao)\n",
    "\n",
    "‚Üí C·∫ßn s·ª≠ d·ª•ng **Transaction-Weighted Utilization (TWU)** l√†m upper bound ƒë·ªÉ c·∫Øt t·ªâa.\n",
    "\n",
    "### 1.3 Transaction-Weighted Utilization (TWU)\n",
    "\n",
    "$$TWU(X) = \\sum_{T_k \\supseteq X} TU(T_k)$$\n",
    "\n",
    "Trong ƒë√≥ $TU(T_k)$ l√† t·ªïng utility c·ªßa giao d·ªãch $T_k$.\n",
    "\n",
    "**T√≠nh ch·∫•t quan tr·ªçng**: TWU c√≥ t√≠nh ch·∫•t downward closure!\n",
    "- N·∫øu $TWU(X) < minUtil$ ‚Üí X v√† t·∫•t c·∫£ superset c·ªßa X kh√¥ng ph·∫£i High-Utility Itemset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef36443",
   "metadata": {},
   "source": [
    "## Parameters (for papermill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e312e4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# PARAMETERS (for papermill)\n",
    "\n",
    "# ==================== ƒê∆Ø·ªúNG D·∫™N D·ªÆ LI·ªÜU ====================\n",
    "CLEANED_DATA_PATH = \"data/processed/cleaned_uk_data.csv\"\n",
    "OUTPUT_DIR = \"data/processed\"\n",
    "HUI_OUTPUT_PATH = \"data/processed/high_utility_itemsets.csv\"\n",
    "\n",
    "# ==================== THAM S·ªê TH·ª¨ NGHI·ªÜM ====================\n",
    "# Ng∆∞·ª°ng utility cho th·ª≠ nghi·ªám so s√°nh\n",
    "TEST_THRESHOLDS = [0.1, 0.05]\n",
    "\n",
    "# Tham s·ªë c≈© (deprecated, ch·ªâ ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi papermill)\n",
    "MIN_UTILITY_PERCENT = 0.1  \n",
    "MIN_UTILITY_ABSOLUTE = 0  # ƒê·∫∑t > 0 n·∫øu mu·ªën d√πng ng∆∞·ª°ng tuy·ªát ƒë·ªëi\n",
    "\n",
    "# ƒê·ªô d√†i t·ªëi ƒëa c·ªßa itemset\n",
    "MAX_ITEMSET_LENGTH = 2  # C√≥ th·ªÉ test v·ªõi 3, 4\n",
    "\n",
    "# ‚è±Ô∏è TIMEOUT CONFIGURATION (gi√¢y)\n",
    "# Timeout cho m·ªói experiment, t·ª± ƒë·ªông tƒÉng theo max_length\n",
    "TIMEOUT_CONFIG = {\n",
    "    1: 180,\n",
    "    2: 300\n",
    "}\n",
    "\n",
    "# ==================== C·ªòT D·ªÆ LI·ªÜU ====================\n",
    "INVOICE_COL = \"InvoiceNo\"\n",
    "ITEM_COL = \"Description\"\n",
    "QUANTITY_COL = \"Quantity\"\n",
    "PRICE_COL = \"UnitPrice\"\n",
    "TOTAL_COL = \"TotalPrice\"\n",
    "\n",
    "# ==================== T√ôY CH·ªåN HI·ªÇN TH·ªä ====================\n",
    "# B·∫≠t/t·∫Øt c√°c bi·ªÉu ƒë·ªì\n",
    "PLOT_TOP_HUI = True\n",
    "PLOT_COMPARISON = True\n",
    "PLOT_UTILITY_DISTRIBUTION = True\n",
    "\n",
    "# B·∫≠t/t·∫Øt ph√¢n t√≠ch k-itemsets (3.1, 3.2)\n",
    "RUN_ANALYSIS = True\n",
    "\n",
    "# S·ªë l∆∞·ª£ng top itemsets ƒë·ªÉ hi·ªÉn th·ªã\n",
    "TOP_N = 5\n",
    "\n",
    "# ==================== M√ÄU S·∫ÆC CH·ª¶ ƒê·∫†O ====================\n",
    "COLOR_BLUE = '#3498db'    # Xanh d∆∞∆°ng - cho Frequency/Volume\n",
    "COLOR_GREEN = '#2ecc71'   # Xanh l√° c√¢y - cho Utility/Profit  \n",
    "COLOR_ORANGE = '#e67e22'  # Cam - cho Highlights/Important\n",
    "COLOR_GRAY = '#95a5a6'    # X√°m - cho c√°c m·ª•c kh√°c\n",
    "COLOR_RED = '#e74c3c'     # ƒê·ªè - cho c·∫£nh b√°o\n",
    "\n",
    "# ==================== G·ª¢I √ù T·ªêI ∆ØU ====================\n",
    "# üí° ƒê·ªÉ tƒÉng t·ªëc ƒë·ªô:\n",
    "# - MIN_UTILITY_PERCENT: 0.001 (ch·∫≠m) -> 0.005 (v·ª´a) -> 0.01 (nhanh)\n",
    "# - MAX_ITEMSET_LENGTH: 3 (ch·∫≠m) -> 2 (nhanh) -> 1 (r·∫•t nhanh, ch·ªâ single items)\n",
    "# - TIMEOUT: TƒÉng n·∫øu c·∫ßn th·ªùi gian ch·∫°y l√¢u h∆°n\n",
    "# \n",
    "# üéØ C·∫•u h√¨nh khuy·∫øn ngh·ªã cho demo nhanh:\n",
    "#    MIN_UTILITY_PERCENT=0.01, MAX_ITEMSET_LENGTH=2, TIMEOUT=600s\n",
    "\n",
    "# #    TEST_THRESHOLDS=[0.1, 0.05, 0.025, 0.0125], MAX_ITEMSET_LENGTH=3, TIMEOUT=1800s\n",
    "# üî¨ C·∫•u h√¨nh khuy·∫øn ngh·ªã cho nghi√™n c·ª©u ƒë·∫ßy ƒë·ªß:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bef8229",
   "metadata": {},
   "source": [
    "## 2. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ddc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_TIMEOUT = TIMEOUT_CONFIG.get(str(MAX_ITEMSET_LENGTH), 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515eeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìä THAM S·ªê TH·ª¨ NGHI·ªÜM\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test thresholds: {[f'{t*100}%' for t in TEST_THRESHOLDS]}\")\n",
    "print(f\"Max itemset length: {MAX_ITEMSET_LENGTH}\")\n",
    "print(f\"‚è±Ô∏è Timeout per experiment: {EXPERIMENT_TIMEOUT}s ({EXPERIMENT_TIMEOUT/60:.1f} minutes)\")\n",
    "print(f\"üíæ Data path: {CLEANED_DATA_PATH}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd905ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# X√°c ƒë·ªãnh project_root linh ho·∫°t\n",
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) == \"notebooks\":\n",
    "    project_root = os.path.abspath(\"../..\")\n",
    "elif \"Lab_PhatTrien_5315\" in cwd:\n",
    "    project_root = os.path.abspath(os.path.join(cwd, \"..\", \"..\"))\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# T·∫°o output directory ngay t·ª´ ƒë·∫ßu\n",
    "LAB_OUTPUT_DIR = os.path.join(project_root, \"Lab_PhatTrien_5315\", \"output\")\n",
    "os.makedirs(LAB_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Style cho bi·ªÉu ƒë·ªì\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"axes.titlesize\"] = 14\n",
    "plt.rcParams[\"axes.labelsize\"] = 12\n",
    "\n",
    "# 3 M√ÄU CH·ª¶ ƒê·∫†O\n",
    "COLOR_BLUE = '#3498db'    # Xanh d∆∞∆°ng - cho Frequency/Volume\n",
    "COLOR_GREEN = '#2ecc71'   # Xanh l√° c√¢y - cho Utility/Profit  \n",
    "COLOR_ORANGE = '#e67e22'  # Cam - cho Highlights/Important\n",
    "\n",
    "# M√†u ph·ª•\n",
    "COLOR_GRAY = '#95a5a6'\n",
    "COLOR_RED = '#e74c3c'\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Output directory: {LAB_OUTPUT_DIR}\")\n",
    "print(f\"\\nüé® M√†u ch·ªß ƒë·∫°o: Xanh d∆∞∆°ng ({COLOR_BLUE}), Xanh l√° ({COLOR_GREEN}), Cam ({COLOR_ORANGE})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3fe62",
   "metadata": {},
   "source": [
    "### 2.1 Timeout v√† Logging Utilities\n",
    "\n",
    "ƒê·ªãnh nghƒ©a c√°c h√†m ti·ªán √≠ch ƒë·ªÉ:\n",
    "- **Timeout protection**: Gi·ªõi h·∫°n th·ªùi gian ch·∫°y c·ªßa c√°c experiment ƒë·ªÉ tr√°nh treo h·ªá th·ªëng\n",
    "- **Logging**: Ghi log v·ªõi timestamp, m√†u s·∫Øc theo level, v√† l∆∞u v√†o file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import functools\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    \"\"\"Exception raised when a function exceeds time limit.\"\"\"\n",
    "    pass\n",
    "\n",
    "def timeout_decorator(timeout_seconds):\n",
    "    \"\"\"\n",
    "    Decorator ƒë·ªÉ gi·ªõi h·∫°n th·ªùi gian ch·∫°y c·ªßa function.\n",
    "    \n",
    "    Args:\n",
    "        timeout_seconds: Th·ªùi gian t·ªëi ƒëa (gi√¢y)\n",
    "        \n",
    "    Returns:\n",
    "        Decorated function v·ªõi timeout protection\n",
    "        \n",
    "    Raises:\n",
    "        TimeoutError: N·∫øu function ch·∫°y qu√° timeout_seconds\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            result = [TimeoutError(f'Function {func.__name__} exceeded {timeout_seconds}s timeout')]\n",
    "            \n",
    "            def target():\n",
    "                try:\n",
    "                    result[0] = func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    result[0] = e\n",
    "            \n",
    "            thread = threading.Thread(target=target)\n",
    "            thread.daemon = True\n",
    "            thread.start()\n",
    "            thread.join(timeout_seconds)\n",
    "            \n",
    "            if thread.is_alive():\n",
    "                # Thread v·∫´n ch·∫°y = timeout\n",
    "                raise TimeoutError(f'Function {func.__name__} exceeded {timeout_seconds}s timeout')\n",
    "            \n",
    "            if isinstance(result[0], Exception):\n",
    "                raise result[0]\n",
    "            \n",
    "            return result[0]\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def log_progress(message, level='INFO'):\n",
    "    \"\"\"\n",
    "    Ghi log v·ªõi timestamp v√† level.\n",
    "    \n",
    "    Args:\n",
    "        message: N·ªôi dung log\n",
    "        level: M·ª©c ƒë·ªô log (INFO, WARNING, ERROR, SUCCESS, TIMEOUT)\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # M√†u s·∫Øc theo level\n",
    "    colors = {\n",
    "        'INFO': '\\033[94m',      # Blue\n",
    "        'SUCCESS': '\\033[92m',   # Green\n",
    "        'WARNING': '\\033[93m',   # Yellow\n",
    "        'ERROR': '\\033[91m',     # Red\n",
    "        'TIMEOUT': '\\033[95m',   # Magenta\n",
    "        'RESET': '\\033[0m'\n",
    "    }\n",
    "    \n",
    "    color = colors.get(level, colors['INFO'])\n",
    "    reset = colors['RESET']\n",
    "    \n",
    "    log_msg = f\"[{timestamp}][{level}] {message}\"\n",
    "    print(f\"{color}{log_msg}{reset}\")\n",
    "    \n",
    "    # L∆∞u v√†o file log\n",
    "    log_file = os.path.join(LAB_OUTPUT_DIR, 'experiment_log.txt')\n",
    "    with open(log_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(log_msg + '\\n')\n",
    "    \n",
    "    return log_msg\n",
    "\n",
    "# Test logging\n",
    "log_progress(\"Logging system initialized\", \"SUCCESS\")\n",
    "log_progress(\"Timeout protection enabled\", \"SUCCESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfaccf9",
   "metadata": {},
   "source": [
    "## 3. T·∫£i v√† chu·∫©n b·ªã d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch\n",
    "data_path = os.path.join(project_root, CLEANED_DATA_PATH)\n",
    "df = pd.read_csv(data_path, parse_dates=[\"InvoiceDate\"])\n",
    "\n",
    "print(\"=== Th√¥ng tin d·ªØ li·ªáu ===\")\n",
    "print(f\"- S·ªë giao d·ªãch (d√≤ng): {df.shape[0]:,}\")\n",
    "print(f\"- S·ªë c·ªôt: {df.shape[1]}\")\n",
    "print(f\"- S·ªë ho√° ƒë∆°n duy nh·∫•t: {df[INVOICE_COL].nunique():,}\")\n",
    "print(f\"- S·ªë s·∫£n ph·∫©m duy nh·∫•t: {df[ITEM_COL].nunique():,}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53db885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra th√¥ng tin utility\n",
    "print(\"=== Th·ªëng k√™ Utility (TotalPrice) ===\")\n",
    "print(df[TOTAL_COL].describe())\n",
    "\n",
    "total_utility = df[TOTAL_COL].sum()\n",
    "TOTAL_UTILITY = total_utility  # Define global constant for later use\n",
    "print(f\"\\nT·ªïng Utility (Doanh thu) c·ªßa to√†n b·ªô database: ¬£{total_utility:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cc656",
   "metadata": {},
   "source": [
    "### 3.1 Ph√¢n T√≠ch Kh·∫£ NƒÉng T·∫°o K-Itemsets\n",
    "\n",
    "Tr∆∞·ªõc khi ch·∫°y khai th√°c, c·∫ßn ph√¢n t√≠ch xem d·ªØ li·ªáu c√≥ kh·∫£ nƒÉng t·∫°o k-itemsets (2, 3, 4, 5, 6-itemsets) hay kh√¥ng. ƒêi·ªÅu n√†y gi√∫p:\n",
    "- Ch·ªçn `MAX_ITEMSET_LENGTH` ph√π h·ª£p\n",
    "- Tr√°nh l√£ng ph√≠ th·ªùi gian v·ªõi k qu√° l·ªõn\n",
    "- Hi·ªÉu c·∫•u tr√∫c giao d·ªãch trong dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cafa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ANALYSIS:\n",
    "    # Ph√¢n t√≠ch ƒë·ªô d√†i giao d·ªãch\n",
    "    print(\"=\"*80)\n",
    "    print(\"üìä PH√ÇN T√çCH ƒê·ªò D√ÄI GIAO D·ªäCH V√Ä KH·∫¢ NƒÇNG T·∫†O K-ITEMSETS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # T√≠nh s·ªë l∆∞·ª£ng items trong m·ªói h√≥a ƒë∆°n\n",
    "    items_per_invoice = df.groupby(INVOICE_COL)[ITEM_COL].count()\n",
    "\n",
    "    print(\"\\nüìà Th·ªëng k√™ s·ªë l∆∞·ª£ng items/h√≥a ƒë∆°n:\")\n",
    "    print(items_per_invoice.describe().to_string())\n",
    "\n",
    "    # Ph√¢n t√≠ch kh·∫£ nƒÉng t·∫°o k-itemsets\n",
    "    print(\"\\nüîç Kh·∫£ nƒÉng t·∫°o k-itemsets t·ª´ d·ªØ li·ªáu:\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    k_itemset_stats = []\n",
    "    max_k_to_check = 5\n",
    "\n",
    "    for k in range(2, max_k_to_check + 1):\n",
    "        # S·ªë h√≥a ƒë∆°n c√≥ >= k items (c√≥ th·ªÉ t·∫°o k-itemset)\n",
    "        invoices_with_k = (items_per_invoice >= k).sum()\n",
    "        percent = invoices_with_k / len(items_per_invoice) * 100\n",
    "        \n",
    "        # T√≠nh s·ªë l∆∞·ª£ng k-itemsets c√≥ th·ªÉ c√≥ (∆∞·ªõc t√≠nh)\n",
    "        avg_items_qualified = items_per_invoice[items_per_invoice >= k].mean() if invoices_with_k > 0 else 0\n",
    "        \n",
    "        # S·ªë combinations c√≥ th·ªÉ t·ª´ 1 invoice v·ªõi n items: C(n,k)\n",
    "        if avg_items_qualified >= k and k <= 7:  # Gi·ªõi h·∫°n t√≠nh to√°n\n",
    "            from math import comb\n",
    "            avg_combinations = comb(int(avg_items_qualified), k) if avg_items_qualified >= k else 0\n",
    "            total_possible = avg_combinations * invoices_with_k\n",
    "        else:\n",
    "            total_possible = 0\n",
    "        \n",
    "        stat = {\n",
    "            'k': k,\n",
    "            'invoices_count': invoices_with_k,\n",
    "            'invoices_percent': percent,\n",
    "            'avg_items': avg_items_qualified,\n",
    "            'est_combinations': total_possible\n",
    "        }\n",
    "        k_itemset_stats.append(stat)\n",
    "        \n",
    "        # In k·∫øt qu·∫£\n",
    "        status_icon = \"‚úÖ\" if percent >= 70 else (\"‚ö†Ô∏è\" if percent >= 50 else \"üî¥\")\n",
    "        print(f\"{status_icon} {k}-itemsets: {invoices_with_k:,} h√≥a ƒë∆°n ({percent:.1f}%) c√≥ th·ªÉ t·∫°o\")\n",
    "        \n",
    "        # C·∫£nh b√°o n·∫øu qu√° √≠t\n",
    "        if percent < 50:\n",
    "            print(f\"   ‚ö†Ô∏è Ch·ªâ {percent:.1f}% h√≥a ƒë∆°n c√≥ th·ªÉ t·∫°o {k}-itemsets\")\n",
    "        if percent < 10:\n",
    "            print(f\"   üî¥ KH√îNG N√äN d√πng MAX_ITEMSET_LENGTH={k} (qu√° √≠t d·ªØ li·ªáu)\")\n",
    "\n",
    "    # T·∫°o DataFrame ƒë·ªÉ visualize\n",
    "    df_k_stats = pd.DataFrame(k_itemset_stats)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üí° KHUY·∫æN NGH·ªä CHO MAX_ITEMSET_LENGTH:\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # T√¨m k t·ªëi ∆∞u (>= 70% h√≥a ƒë∆°n c√≥ th·ªÉ t·∫°o)\n",
    "    optimal_k_candidates = df_k_stats[df_k_stats['invoices_percent'] >= 70]['k']\n",
    "    optimal_k = optimal_k_candidates.max() if len(optimal_k_candidates) > 0 else 2\n",
    "    practical_k = min(optimal_k, 4)  # Gi·ªõi h·∫°n th·ª±c t·∫ø l√† 4\n",
    "\n",
    "    print(f\"‚úÖ Gi√° tr·ªã t·ªëi ∆∞u: MAX_ITEMSET_LENGTH = {practical_k}\")\n",
    "    current_k_row = df_k_stats[df_k_stats['k']==practical_k].iloc[0]\n",
    "    print(f\"   - {current_k_row['invoices_percent']:.1f}% h√≥a ƒë∆°n c√≥ th·ªÉ t·∫°o {practical_k}-itemsets\")\n",
    "    print(f\"   - C√¢n b·∫±ng t·ªët gi·ªØa coverage v√† performance\")\n",
    "\n",
    "    if MAX_ITEMSET_LENGTH > practical_k:\n",
    "        print(f\"\\n‚ö†Ô∏è C·∫£nh b√°o: MAX_ITEMSET_LENGTH hi·ªán t·∫°i ({MAX_ITEMSET_LENGTH}) > khuy·∫øn ngh·ªã ({practical_k})\")\n",
    "        print(f\"   ‚Üí C√≥ th·ªÉ ch·∫°y l√¢u m√† kh√¥ng t√¨m th√™m nhi·ªÅu patterns h·ªØu √≠ch\")\n",
    "    elif MAX_ITEMSET_LENGTH < practical_k:\n",
    "        print(f\"\\nüí° G·ª£i √Ω: C√≥ th·ªÉ tƒÉng MAX_ITEMSET_LENGTH l√™n {practical_k} ƒë·ªÉ t√¨m th√™m patterns\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ MAX_ITEMSET_LENGTH hi·ªán t·∫°i ({MAX_ITEMSET_LENGTH}) ph√π h·ª£p!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è B·ªè qua ph√¢n t√≠ch 3.1 (RUN_ANALYSIS=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57060ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ANALYSIS:\n",
    "    # Visualization: Bi·ªÉu ƒë·ªì ph√¢n t√≠ch k-itemsets\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Plot 1: Histogram ƒë·ªô d√†i giao d·ªãch\n",
    "    ax1 = axes[0]\n",
    "    items_per_invoice_clipped = items_per_invoice.clip(upper=items_per_invoice.quantile(0.95))\n",
    "    ax1.hist(items_per_invoice_clipped, bins=50, color=COLOR_BLUE, edgecolor='white', alpha=0.7)\n",
    "    ax1.axvline(items_per_invoice.median(), color=COLOR_ORANGE, linestyle='--', linewidth=2, \n",
    "                label=f'Median: {items_per_invoice.median():.0f} items')\n",
    "    ax1.axvline(items_per_invoice.mean(), color=COLOR_GREEN, linestyle='--', linewidth=2,\n",
    "                label=f'Mean: {items_per_invoice.mean():.1f} items')\n",
    "    ax1.set_xlabel('S·ªë l∆∞·ª£ng items/h√≥a ƒë∆°n', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('S·ªë h√≥a ƒë∆°n', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Ph√¢n Ph·ªëi ƒê·ªô D√†i Giao D·ªãch', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: % h√≥a ƒë∆°n c√≥ th·ªÉ t·∫°o k-itemsets\n",
    "    ax2 = axes[1]\n",
    "    k_values = df_k_stats['k'].values[:8]  # Hi·ªÉn th·ªã ƒë·∫øn 9-itemsets\n",
    "    percentages = df_k_stats['invoices_percent'].values[:8]\n",
    "\n",
    "    bars = ax2.bar(k_values, percentages, color=COLOR_GREEN, edgecolor='white', linewidth=1.5)\n",
    "    # T√¥ m√†u kh√°c cho c√°c bar < 50%\n",
    "    for i, (bar, pct) in enumerate(zip(bars, percentages)):\n",
    "        if pct < 70:\n",
    "            bar.set_color(COLOR_ORANGE)\n",
    "        if pct < 50:\n",
    "            bar.set_color(COLOR_RED)\n",
    "        # Th√™m label\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                 f'{pct:.1f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "    ax2.axhline(y=70, color='gray', linestyle='--', alpha=0.5, linewidth=2, label='Ng∆∞·ª°ng khuy·∫øn ngh·ªã (70%)')\n",
    "    ax2.set_xlabel('k (ƒë·ªô d√†i itemset)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('% h√≥a ƒë∆°n c√≥ th·ªÉ t·∫°o k-itemset', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Kh·∫£ NƒÉng T·∫°o K-Itemsets (%)', fontsize=13, fontweight='bold')\n",
    "    ax2.set_ylim(0, 105)\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Plot 3: S·ªë l∆∞·ª£ng combinations ∆∞·ªõc t√≠nh (log scale)\n",
    "    ax3 = axes[2]\n",
    "    k_values_calc = df_k_stats[df_k_stats['est_combinations'] > 0]['k'].values\n",
    "    combinations = df_k_stats[df_k_stats['est_combinations'] > 0]['est_combinations'].values\n",
    "\n",
    "    if len(combinations) > 0:\n",
    "        combinations_log = np.log10(combinations)\n",
    "        bars3 = ax3.bar(k_values_calc, combinations_log, color=COLOR_BLUE, edgecolor='white', linewidth=1.5)\n",
    "        \n",
    "        # Th√™m annotation\n",
    "        for bar, k, comb in zip(bars3, k_values_calc, combinations):\n",
    "            height = bar.get_height()\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2, height + 0.1,\n",
    "                    f'{comb:.1e}', ha='center', va='bottom', fontsize=8, rotation=45)\n",
    "        \n",
    "        ax3.set_xlabel('k (ƒë·ªô d√†i itemset)', fontsize=11, fontweight='bold')\n",
    "        ax3.set_ylabel('Log‚ÇÅ‚ÇÄ(S·ªë combinations ∆∞·ªõc t√≠nh)', fontsize=11, fontweight='bold')\n",
    "        ax3.set_title('ƒê·ªô Ph·ª©c T·∫°p T√≠nh To√°n (Log Scale)', fontsize=13, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Th√™m annotation cho MAX_ITEMSET_LENGTH hi·ªán t·∫°i\n",
    "    for ax in [ax2, ax3]:\n",
    "        ax.axvline(x=MAX_ITEMSET_LENGTH, color=COLOR_RED, linestyle='-', linewidth=3, alpha=0.6,\n",
    "                   label=f'MAX_ITEMSET_LENGTH = {MAX_ITEMSET_LENGTH}')\n",
    "        ax.legend(fontsize=10)\n",
    "\n",
    "    plt.suptitle('PH√ÇN T√çCH KH·∫¢ NƒÇNG T·∫†O K-ITEMSETS T·ª™ D·ªÆ LI·ªÜU', \n",
    "                 fontsize=15, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # L∆∞u bi·ªÉu ƒë·ªì\n",
    "    chart_path = os.path.join(LAB_OUTPUT_DIR, '3.1 Phan Tich Kha Nang Tao K-Itemsets.png')\n",
    "    plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c11f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_ANALYSIS:\n",
    "    # Ph√¢n t√≠ch chi ti·∫øt cho MAX_ITEMSET_LENGTH hi·ªán t·∫°i\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üìã PH√ÇN T√çCH CHI TI·∫æT CHO MAX_ITEMSET_LENGTH = {MAX_ITEMSET_LENGTH}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # L·∫•y th√¥ng tin cho k hi·ªán t·∫°i\n",
    "    current_k_info = df_k_stats[df_k_stats['k'] == MAX_ITEMSET_LENGTH].iloc[0]\n",
    "\n",
    "    print(f\"\\n‚úÖ V·ªõi MAX_ITEMSET_LENGTH = {MAX_ITEMSET_LENGTH}:\")\n",
    "    print(f\"   ‚Ä¢ {current_k_info['invoices_count']:,} h√≥a ƒë∆°n ({current_k_info['invoices_percent']:.1f}%) c√≥ th·ªÉ t·∫°o {MAX_ITEMSET_LENGTH}-itemsets\")\n",
    "    print(f\"   ‚Ä¢ Trung b√¨nh {current_k_info['avg_items']:.1f} items trong c√°c h√≥a ƒë∆°n ƒë·ªß ƒëi·ªÅu ki·ªán\")\n",
    "\n",
    "    # ƒê√°nh gi√° coverage\n",
    "    if current_k_info['invoices_percent'] >= 80:\n",
    "        print(f\"   ‚Ä¢ ‚úÖ R·∫§T T·ªêT - coverage cao ({current_k_info['invoices_percent']:.1f}% ‚â• 80%)\")\n",
    "    elif current_k_info['invoices_percent'] >= 70:\n",
    "        print(f\"   ‚Ä¢ ‚úÖ T·ªêT - coverage t·ªët ({current_k_info['invoices_percent']:.1f}% ‚â• 70%)\")\n",
    "    elif current_k_info['invoices_percent'] >= 50:\n",
    "        print(f\"   ‚Ä¢ ‚ö†Ô∏è CH·∫§P NH·∫¨N ƒê∆Ø·ª¢C - coverage trung b√¨nh ({current_k_info['invoices_percent']:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ üî¥ KH√îNG T·ªêI ∆ØU - coverage th·∫•p ({current_k_info['invoices_percent']:.1f}% < 50%)\")\n",
    "\n",
    "    # ∆Ø·ªõc t√≠nh th·ªùi gian ch·∫°y\n",
    "    if MAX_ITEMSET_LENGTH <= 2:\n",
    "        print(f\"   ‚Ä¢ ‚ö° T·ªëc ƒë·ªô: NHANH ({MAX_ITEMSET_LENGTH}-itemsets - v√†i ph√∫t)\")\n",
    "    elif MAX_ITEMSET_LENGTH == 3:\n",
    "        print(f\"   ‚Ä¢ ‚è±Ô∏è T·ªëc ƒë·ªô: TRUNG B√åNH ({MAX_ITEMSET_LENGTH}-itemsets - 10-30 ph√∫t)\")\n",
    "    elif MAX_ITEMSET_LENGTH == 4:\n",
    "        print(f\"   ‚Ä¢ üêå T·ªëc ƒë·ªô: CH·∫¨M ({MAX_ITEMSET_LENGTH}-itemsets - 30-60 ph√∫t)\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ üê¢ T·ªëc ƒë·ªô: R·∫§T CH·∫¨M ({MAX_ITEMSET_LENGTH}-itemsets - c√≥ th·ªÉ > 1 gi·ªù)\")\n",
    "\n",
    "    # Th·ªëng k√™ t·ªïng quan\n",
    "    print(\"\\nüìä T·ªïng quan coverage cho c√°c k-itemsets:\")\n",
    "    print(\"-\"*80)\n",
    "    for idx, row in df_k_stats.head(6).iterrows():\n",
    "        k = int(row['k'])\n",
    "        pct = row['invoices_percent']\n",
    "        status = \"‚úÖ\" if pct >= 70 else (\"‚ö†Ô∏è\" if pct >= 50 else \"üî¥\")\n",
    "        marker = \" ‚Üê Hi·ªán t·∫°i\" if k == MAX_ITEMSET_LENGTH else \"\"\n",
    "        print(f\"{status} {k}-itemsets: {pct:5.1f}% coverage{marker}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523e5e4",
   "metadata": {},
   "source": [
    "### 3.2 Ph√¢n T√≠ch Ph√¢n B·ªë Utility c·ªßa K-Itemsets\n",
    "\n",
    "ƒê·ªÉ ƒëi·ªÅu ch·ªânh `MIN_UTILITY_PERCENT` v√† `TEST_THRESHOLDS` m·ªôt c√°ch hi·ªáu qu·∫£, ta c·∫ßn hi·ªÉu ph√¢n b·ªë utility c·ªßa c√°c k-itemsets c√≥ th·ªÉ t·∫°o ra t·ª´ d·ªØ li·ªáu.\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- T√≠nh utility trung b√¨nh, median, percentiles cho t·ª´ng lo·∫°i k-itemset (k=2‚Üí5)\n",
    "- X√°c ƒë·ªãnh t·ª∑ l·ªá itemsets c√≥ utility ‚â• MIN_UTILITY_THRESHOLD\n",
    "- Tr·ª±c quan h√≥a ph√¢n b·ªë ƒë·ªÉ t√¨m threshold t·ªëi ∆∞u tr√°nh timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not RUN_ANALYSIS:\n",
    "    print(\"‚è≠Ô∏è B·ªè qua ph√¢n t√≠ch 3.2 (RUN_ANALYSIS=False)\")\n",
    "else:\n",
    "    # Ph√¢n t√≠ch utility distribution cho k-itemsets\n",
    "    import itertools\n",
    "    from collections import defaultdict\n",
    "    import numpy as np\n",
    "\n",
    "    # Configuration\n",
    "    max_k_to_check = 3\n",
    "    sample_ratio = 0.1e-2\n",
    "    np.random.seed(42)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"üîç PH√ÇN T√çCH PH√ÇN B·ªê UTILITY C·ª¶A K-ITEMSETS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"üìä D·ªØ li·ªáu: {len(df)} rows, {df[INVOICE_COL].nunique()} invoices\")\n",
    "    print(f\"üì¶ Ph·∫°m vi: 2-itemsets ‚Üí {max_k_to_check}-itemsets\")\n",
    "    print(f\"üé≤ Sample ratio: {sample_ratio*100:.0f}% invoices\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # T√≠nh utility cho t·ª´ng invoice\n",
    "    invoice_items = df.groupby(INVOICE_COL).apply(\n",
    "        lambda x: list(zip(x[ITEM_COL], x[TOTAL_COL]))\n",
    "    ).to_dict()\n",
    "\n",
    "    # Sample invoices ƒë·ªÉ gi·∫£m th·ªùi gian t√≠nh to√°n\n",
    "    all_invoices = list(invoice_items.keys())\n",
    "    sample_size = max(100, int(len(all_invoices) * sample_ratio))\n",
    "    sample_indices = np.random.choice(len(all_invoices), size=sample_size, replace=False)\n",
    "    sampled_invoices = [all_invoices[i] for i in sample_indices]  # Gi·ªØ nguy√™n ki·ªÉu d·ªØ li·ªáu g·ªëc\n",
    "\n",
    "    print(f\"\\n‚úÖ ƒê√£ sample {len(sampled_invoices):,} / {len(all_invoices):,} invoices\")\n",
    "\n",
    "    # Dictionary ƒë·ªÉ l∆∞u utility c·ªßa m·ªói k-itemset\n",
    "    k_itemsets_utilities = defaultdict(list)\n",
    "\n",
    "    print(\"\\n‚è≥ ƒêang t√≠nh utility cho t·ª´ng k-itemset...\")\n",
    "    for idx, invoice_id in enumerate(sampled_invoices, 1):\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"   Processing invoice {idx}/{len(sampled_invoices)}...\", end='\\r')\n",
    "        \n",
    "        items_with_utility = invoice_items[invoice_id]\n",
    "        items = [item for item, _ in items_with_utility]\n",
    "        utility_map = {item: utility for item, utility in items_with_utility}\n",
    "        \n",
    "        # T√≠nh utility cho m·ªói k\n",
    "        for k in range(2, min(max_k_to_check + 1, len(items) + 1)):\n",
    "            for combo in itertools.combinations(items, k):\n",
    "                total_utility = sum(utility_map[item] for item in combo)\n",
    "                k_itemsets_utilities[k].append(total_utility)\n",
    "\n",
    "    print(f\"\\n‚úÖ Ho√†n th√†nh ph√¢n t√≠ch {len(sampled_invoices):,} invoices\")\n",
    "\n",
    "    # T√≠nh th·ªëng k√™ cho m·ªói k\n",
    "    stats_summary = []\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà TH·ªêNG K√ä UTILITY THEO K-ITEMSETS (ƒê·ªÇ CH·ªåN THRESHOLD PH√ô H·ª¢P)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"üí° S·ª≠ d·ª•ng c√°c percentiles d∆∞·ªõi ƒë√¢y ƒë·ªÉ ch·ªçn MIN_UTILITY_PERCENT h·ª£p l√Ω\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    for k in range(2, max_k_to_check + 1):\n",
    "        utilities = k_itemsets_utilities[k]\n",
    "        if len(utilities) == 0:\n",
    "            print(f\"\\n‚ö†Ô∏è {k}-itemsets: Kh√¥ng c√≥ d·ªØ li·ªáu\")\n",
    "            continue\n",
    "        \n",
    "        utilities_arr = np.array(utilities)\n",
    "        \n",
    "        # T√≠nh c√°c percentiles\n",
    "        p25, p50, p75, p90, p95, p99 = np.percentile(utilities_arr, [25, 50, 75, 90, 95, 99])\n",
    "        \n",
    "        stats_summary.append({\n",
    "            'k': k,\n",
    "            'count': len(utilities_arr),\n",
    "            'mean': utilities_arr.mean(),\n",
    "            'median': p50,\n",
    "            'std': utilities_arr.std(),\n",
    "            'min': utilities_arr.min(),\n",
    "            'max': utilities_arr.max(),\n",
    "            'p25': p25,\n",
    "            'p75': p75,\n",
    "            'p90': p90,\n",
    "            'p95': p95,\n",
    "            'p99': p99,\n",
    "            # T√≠nh % c·ªßa max ƒë·ªÉ g·ª£i √Ω threshold\n",
    "            'p99_percent_of_total': (p99 / TOTAL_UTILITY) * 100,\n",
    "            'max_percent_of_total': (utilities_arr.max() / TOTAL_UTILITY) * 100\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*80}\")\n",
    "        print(f\"üîπ {k}-ITEMSETS\")\n",
    "        print(f\"{'‚îÄ'*80}\")\n",
    "        print(f\"  üìä T·ªïng s·ªë: {len(utilities_arr):,} itemsets\")\n",
    "        print(f\"  üìà Trung b√¨nh: ¬£{utilities_arr.mean():,.2f}\")\n",
    "        print(f\"  üìä Median: ¬£{p50:,.2f}\")\n",
    "        print(f\"  üìè Std Dev: ¬£{utilities_arr.std():,.2f}\")\n",
    "        print(f\"  üîΩ Min: ¬£{utilities_arr.min():,.2f}\")\n",
    "        print(f\"  üîº Max: ¬£{utilities_arr.max():,.2f}\")\n",
    "        print(f\"\\n  üìä Percentiles:\")\n",
    "        print(f\"     25%: ¬£{p25:,.2f}\")\n",
    "        print(f\"     50%: ¬£{p50:,.2f}\")\n",
    "        print(f\"     75%: ¬£{p75:,.2f}\")\n",
    "        print(f\"     90%: ¬£{p90:,.2f}\")\n",
    "        print(f\"     95%: ¬£{p95:,.2f}\")\n",
    "        print(f\"     99%: ¬£{p99:,.2f}\")\n",
    "\n",
    "        \n",
    "        # G·ª£i √Ω threshold d·ª±a tr√™n percentiles\n",
    "        p99_pct = (p99 / TOTAL_UTILITY) * 100\n",
    "        max_pct = (utilities_arr.max() / TOTAL_UTILITY) * 100\n",
    "        print(f\"\\n  üí° G·ª¢I √ù THRESHOLD (d·ª±a tr√™n TOTAL_UTILITY = ¬£{TOTAL_UTILITY:,.0f}):\")\n",
    "        print(f\"     P99 = {p99_pct:.6f}% c·ªßa total ‚Üí MIN_UTILITY_PERCENT ‚â• {p99_pct:.4f}% ƒë·ªÉ l·ªçc top 1%\")\n",
    "        print(f\"     Max = {max_pct:.6f}% c·ªßa total ‚Üí Utility cao nh·∫•t trong 1 transaction\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_stats = pd.DataFrame(stats_summary)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ Ho√†n th√†nh ph√¢n t√≠ch utility distribution\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94593e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_ANALYSIS:\n",
    "    print(\"‚è≠Ô∏è B·ªè qua visualization 3.2 (RUN_ANALYSIS=False)\")\n",
    "else:\n",
    "    # Visualization: Ph√¢n b·ªë utility theo k-itemsets\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']\n",
    "\n",
    "    # 1. Box plot - So s√°nh ph√¢n b·ªë utility\n",
    "    ax1 = axes[0, 0]\n",
    "    box_data = [k_itemsets_utilities[k] for k in range(2, max_k_to_check + 1)]\n",
    "    bp = ax1.boxplot(box_data, labels=[f\"{k}-itemsets\" for k in range(2, max_k_to_check + 1)],\n",
    "                      patch_artist=True, showmeans=True, meanline=True)\n",
    "\n",
    "    # T√¥ m√†u cho boxes\n",
    "    for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "\n",
    "    ax1.set_ylabel('Utility (¬£)', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Ph√¢n B·ªë Utility theo K-Itemsets (Box Plot)', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_yscale('log')  # Log scale ƒë·ªÉ d·ªÖ nh√¨n\n",
    "\n",
    "    # 2. Bar chart - So s√°nh P99 v√† Max utility theo k\n",
    "    ax2 = axes[0, 1]\n",
    "    x_pos = np.arange(len(df_stats))\n",
    "    bar_width = 0.35\n",
    "\n",
    "    bars1 = ax2.bar(x_pos - bar_width/2, df_stats['p99'], bar_width, color='#2E86AB', alpha=0.7, label='P99')\n",
    "    bars2 = ax2.bar(x_pos + bar_width/2, df_stats['max'], bar_width, color='#E74C3C', alpha=0.7, label='Max')\n",
    "\n",
    "    # Th√™m labels\n",
    "    for i, (idx, row) in enumerate(df_stats.iterrows()):\n",
    "        ax2.text(i - bar_width/2, row['p99'], f\"¬£{row['p99']:,.0f}\", ha='center', va='bottom', fontsize=8, rotation=45)\n",
    "        ax2.text(i + bar_width/2, row['max'], f\"¬£{row['max']:,.0f}\", ha='center', va='bottom', fontsize=8, rotation=45)\n",
    "\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels([f\"{int(row['k'])}-itemsets\" for _, row in df_stats.iterrows()])\n",
    "    ax2.set_ylabel('Utility (¬£)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('P99 vs Max Utility (ƒë·ªÉ ch·ªçn threshold)', fontsize=12, fontweight='bold')\n",
    "    ax2.legend(fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # 3. Histogram - Ph√¢n b·ªë utility cho t·ª´ng k\n",
    "    ax3 = axes[1, 0]\n",
    "    for k, color in zip(range(2, max_k_to_check + 1), colors):\n",
    "        utilities = k_itemsets_utilities[k]\n",
    "        if len(utilities) > 0:\n",
    "            ax3.hist(utilities, bins=50, alpha=0.5, color=color, label=f'{k}-itemsets', density=True)\n",
    "\n",
    "    ax3.set_xlabel('Utility (¬£)', fontsize=11, fontweight='bold')\n",
    "    ax3.set_ylabel('Density', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Ph√¢n B·ªë Utility (Histogram)', fontsize=12, fontweight='bold')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.legend(fontsize=9)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4. Summary statistics table\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('tight')\n",
    "    ax4.axis('off')\n",
    "\n",
    "    # T·∫°o table data - th·ªëng k√™ thu·∫ßn t√∫y\n",
    "    table_data = []\n",
    "    table_data.append(['K', 'Count', 'Mean (¬£)', 'Median (¬£)', 'P95 (¬£)', 'P99 (¬£)', 'Max (¬£)'])\n",
    "    for _, row in df_stats.iterrows():\n",
    "        table_data.append([\n",
    "            f\"{int(row['k'])}\",\n",
    "            f\"{int(row['count']):,}\",\n",
    "            f\"¬£{row['mean']:,.0f}\",\n",
    "            f\"¬£{row['median']:,.0f}\",\n",
    "            f\"¬£{row['p95']:,.0f}\",\n",
    "            f\"¬£{row['p99']:,.0f}\",\n",
    "            f\"¬£{row['max']:,.0f}\"\n",
    "        ])\n",
    "\n",
    "    table = ax4.table(cellText=table_data, cellLoc='center', loc='center',\n",
    "                      colWidths=[0.08, 0.18, 0.15, 0.15, 0.15, 0.15, 0.15])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "\n",
    "    # Style header row\n",
    "    for i in range(len(table_data[0])):\n",
    "        cell = table[(0, i)]\n",
    "        cell.set_facecolor('#2E86AB')\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "\n",
    "    # Alternate row colors\n",
    "    for i in range(1, len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i % 2 == 0:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "\n",
    "    ax4.set_title('B·∫£ng T·ªïng H·ª£p Th·ªëng K√™', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # L∆∞u bi·ªÉu ƒë·ªì\n",
    "    chart_path = os.path.join(LAB_OUTPUT_DIR, '3.2 Phan Bo Utility cua K-Itemsets.png')\n",
    "    plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbaffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_ANALYSIS:\n",
    "    print(\"‚è≠Ô∏è B·ªè qua CDF visualization (RUN_ANALYSIS=False)\")\n",
    "else:\n",
    "    # Cumulative Distribution Function (CDF) ƒë·ªÉ t√¨m threshold t·ªëi ∆∞u\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # 1. CDF cho t·ª´ng k-itemset\n",
    "    ax1 = axes[0]\n",
    "    for k, color in zip(range(2, max_k_to_check + 1), colors):\n",
    "        utilities = np.sort(k_itemsets_utilities[k])\n",
    "        if len(utilities) > 0:\n",
    "            cdf = np.arange(1, len(utilities) + 1) / len(utilities) * 100\n",
    "            ax1.plot(utilities, cdf, color=color, linewidth=2, label=f'{k}-itemsets', alpha=0.8)\n",
    "\n",
    "    # Th√™m c√°c ƒë∆∞·ªùng percentile reference\n",
    "    p99_max = df_stats['p99'].max()\n",
    "    ax1.axvline(x=p99_max, color='orange', linestyle='--', linewidth=2, \n",
    "                label=f'P99 Max = ¬£{p99_max:,.0f}')\n",
    "\n",
    "    ax1.set_xlabel('Utility (¬£)', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('Cumulative % of Itemsets', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Cumulative Distribution Function (CDF)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.legend(fontsize=9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. ƒê·ªÅ xu·∫•t thresholds d·ª±a tr√™n percentiles c·ªßa DATA (kh√¥ng ph·∫£i MIN_UTILITY)\n",
    "    ax2 = axes[1]\n",
    "    ax2.axis('tight')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # T·∫°o b·∫£ng ƒë·ªÅ xu·∫•t thresholds d·ª±a tr√™n DATA PERCENTILES\n",
    "    threshold_suggestions = []\n",
    "    threshold_suggestions.append(['Percentile', 'Utility Value', '% of TOTAL_UTILITY', 'Use Case'])\n",
    "\n",
    "    # T√≠nh percentiles t·ª´ t·∫•t c·∫£ utilities\n",
    "    all_utilities = []\n",
    "    for k in range(2, max_k_to_check + 1):\n",
    "        all_utilities.extend(k_itemsets_utilities[k])\n",
    "    all_utilities = np.array(all_utilities)\n",
    "\n",
    "    # C√°c m·ª©c percentile ƒë·ªÉ g·ª£i √Ω\n",
    "    percentile_levels = [\n",
    "        (50, 'P50 (Median)', 'L·ªçc 50% th·∫•p nh·∫•t'),\n",
    "        (75, 'P75', 'Top 25% itemsets'),\n",
    "        (90, 'P90', 'Top 10% itemsets'),\n",
    "        (95, 'P95', 'Top 5% itemsets'),\n",
    "        (99, 'P99', 'Top 1% itemsets'),\n",
    "        (99.9, 'P99.9', 'Top 0.1% itemsets'),\n",
    "    ]\n",
    "\n",
    "    for pct_level, pct_name, use_case in percentile_levels:\n",
    "        threshold_value = np.percentile(all_utilities, pct_level)\n",
    "        pct_of_total = (threshold_value / TOTAL_UTILITY) * 100\n",
    "        \n",
    "        threshold_suggestions.append([\n",
    "            pct_name,\n",
    "            f\"¬£{threshold_value:,.0f}\",\n",
    "            f\"{pct_of_total:.6f}%\",\n",
    "            use_case\n",
    "        ])\n",
    "\n",
    "    # Th√™m d√≤ng cho Max\n",
    "    max_util = all_utilities.max()\n",
    "    max_pct = (max_util / TOTAL_UTILITY) * 100\n",
    "    threshold_suggestions.append([\n",
    "        'Max',\n",
    "        f\"¬£{max_util:,.0f}\",\n",
    "        f\"{max_pct:.6f}%\",\n",
    "        'Utility cao nh·∫•t trong 1 transaction'\n",
    "    ])\n",
    "\n",
    "    table = ax2.table(cellText=threshold_suggestions, cellLoc='left', loc='center',\n",
    "                      colWidths=[0.15, 0.25, 0.25, 0.35])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2.5)\n",
    "\n",
    "    # Style header\n",
    "    for i in range(len(threshold_suggestions[0])):\n",
    "        cell = table[(0, i)]\n",
    "        cell.set_facecolor('#2E86AB')\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "\n",
    "    # Alternate row colors\n",
    "    for i in range(1, len(threshold_suggestions)):\n",
    "        for j in range(len(threshold_suggestions[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i % 2 == 0:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "\n",
    "    ax2.set_title('Percentiles c·ªßa Utility trong 1 Transaction\\n(D√πng ƒë·ªÉ ch·ªçn MIN_UTILITY_PERCENT)', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # L∆∞u bi·ªÉu ƒë·ªì\n",
    "    chart_path = os.path.join(LAB_OUTPUT_DIR, '3.2 CDF va Khuyen Nghi Threshold.png')\n",
    "\n",
    "    plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "    plt.show()\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RUN_ANALYSIS:\n",
    "    print(\"‚è≠Ô∏è B·ªè qua k·∫øt lu·∫≠n ph√¢n t√≠ch (RUN_ANALYSIS=False)\")\n",
    "else:\n",
    "    # K·∫øt lu·∫≠n v√† khuy·∫øn ngh·ªã\n",
    "    print(\"=\"*80)\n",
    "    print(\"üí° K·∫æT LU·∫¨N & KHUY·∫æN NGH·ªä CH·ªåN MIN_UTILITY_PERCENT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Hi·ªÉn th·ªã t·ªïng quan\n",
    "    print(f\"\\nüìä T·ªîNG UTILITY C·ª¶A DATABASE: ¬£{TOTAL_UTILITY:,.2f}\")\n",
    "\n",
    "    print(\"\\n1Ô∏è‚É£ TH·ªêNG K√ä UTILITY TRONG 1 TRANSACTION:\")\n",
    "    for _, row in df_stats.iterrows():\n",
    "        k = int(row['k'])\n",
    "        print(f\"   ‚îî‚îÄ {k}-itemsets: Mean=¬£{row['mean']:,.2f}, Max=¬£{row['max']:,.2f}, P99=¬£{row['p99']:,.2f}\")\n",
    "\n",
    "    print(\"\\n2Ô∏è‚É£ ƒê·ªÄ XU·∫§T MIN_UTILITY_PERCENT:\")\n",
    "    print(\"   ‚ö†Ô∏è L∆ØU √ù: Trong HUIM, utility c·ªßa 1 itemset = T·ªîNG utility tr√™n T·∫§T C·∫¢ transactions\")\n",
    "    print(\"   (Kh√¥ng ph·∫£i utility trong 1 transaction nh∆∞ th·ªëng k√™ tr√™n)\")\n",
    "\n",
    "    # ƒê·ªÅ xu·∫•t d·∫£i thresholds d·ª±a tr√™n percentiles\n",
    "    p99_avg = df_stats['p99'].mean()\n",
    "    max_avg = df_stats['max'].mean()\n",
    "\n",
    "    # T√≠nh % so v·ªõi TOTAL_UTILITY\n",
    "    pct_p99 = (p99_avg / TOTAL_UTILITY) * 100\n",
    "    pct_max = (max_avg / TOTAL_UTILITY) * 100\n",
    "\n",
    "    print(f\"\\n   üìà D·ª±a tr√™n ph√¢n b·ªë utility trong data:\")\n",
    "    print(f\"      ‚Ä¢ P99 trung b√¨nh: ¬£{p99_avg:,.2f} = {pct_p99:.6f}% c·ªßa TOTAL_UTILITY\")\n",
    "    print(f\"      ‚Ä¢ Max trung b√¨nh: ¬£{max_avg:,.2f} = {pct_max:.6f}% c·ªßa TOTAL_UTILITY\")\n",
    "\n",
    "    print(\"\\n   üí° G·ª¢I √ù c√°c m·ª©c MIN_UTILITY_PERCENT ƒë·ªÉ th·ª≠ nghi·ªám:\")\n",
    "    print(\"      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "    print(\"      ‚îÇ Threshold %   ‚îÇ Utility Value  ‚îÇ M√¥ t·∫£                       ‚îÇ\")\n",
    "    print(\"      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "    suggested_thresholds = [\n",
    "        (0.001, 'R·∫•t th·∫•p - Nhi·ªÅu patterns'),\n",
    "        (0.005, 'Th·∫•p - Exploratory'),\n",
    "        (0.01, 'Trung b√¨nh - Balanced'),\n",
    "        (0.05, 'Cao - Top performers'),\n",
    "        (0.1, 'R·∫•t cao - Elite items'),\n",
    "    ]\n",
    "    for pct, desc in suggested_thresholds:\n",
    "        value = TOTAL_UTILITY * pct\n",
    "        print(f\"      ‚îÇ {pct*100:>6.2f}%       ‚îÇ ¬£{value:>12,.0f} ‚îÇ {desc:<27} ‚îÇ\")\n",
    "    print(\"      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "\n",
    "    print(\"\\n3Ô∏è‚É£ KHUY·∫æN NGH·ªä:\")\n",
    "    print(\"   ‚Ä¢ B·∫Øt ƒë·∫ßu v·ªõi MIN_UTILITY_PERCENT = 0.01 (1%) ƒë·ªÉ c√≥ k·∫øt qu·∫£ nhanh\")\n",
    "    print(\"   ‚Ä¢ N·∫øu ch·∫°y qu√° l√¢u/timeout ‚Üí TƒÇNG threshold\")\n",
    "    print(\"   ‚Ä¢ N·∫øu qu√° √≠t patterns ‚Üí GI·∫¢M threshold\")\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚úÖ S·ª≠ d·ª•ng b·∫£ng tr√™n ƒë·ªÉ ch·ªçn MIN_UTILITY_PERCENT v√† TEST_THRESHOLDS ph√π h·ª£p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0c861",
   "metadata": {},
   "source": [
    "### 3.3 T·ªïng quan d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BI·ªÇU ƒê·ªí 1: T·ªïng quan d·ªØ li·ªáu v·ªõi 3 m√†u ch·ªß ƒë·∫°o\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1.1 Ph√¢n ph·ªëi TotalPrice (Utility)\n",
    "ax1 = axes[0, 0]\n",
    "df[TOTAL_COL].clip(upper=df[TOTAL_COL].quantile(0.95)).hist(\n",
    "    bins=50, ax=ax1, color=COLOR_GREEN, edgecolor='white', alpha=0.8\n",
    ")\n",
    "ax1.axvline(df[TOTAL_COL].mean(), color=COLOR_ORANGE, linestyle='--', linewidth=2, label=f'Mean: ¬£{df[TOTAL_COL].mean():.2f}')\n",
    "ax1.axvline(df[TOTAL_COL].median(), color=COLOR_BLUE, linestyle='--', linewidth=2, label=f'Median: ¬£{df[TOTAL_COL].median():.2f}')\n",
    "ax1.set_title('Ph√¢n ph·ªëi Utility (TotalPrice)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('TotalPrice (¬£)')\n",
    "ax1.set_ylabel('S·ªë giao d·ªãch')\n",
    "ax1.legend()\n",
    "\n",
    "# 1.2 Top 10 s·∫£n ph·∫©m theo Utility\n",
    "ax2 = axes[0, 1]\n",
    "top_utility = df.groupby(ITEM_COL)[TOTAL_COL].sum().nlargest(10)\n",
    "colors_top = [COLOR_GREEN if i < 3 else COLOR_BLUE for i in range(len(top_utility))]\n",
    "ax2.barh(range(len(top_utility)), top_utility.values, color=colors_top)\n",
    "ax2.set_yticks(range(len(top_utility)))\n",
    "ax2.set_yticklabels([name[:30] + '...' if len(name) > 30 else name for name in top_utility.index], fontsize=9)\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_title('Top 10 S·∫£n ph·∫©m theo Utility', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('T·ªïng Utility (¬£)')\n",
    "\n",
    "# 1.3 Top 10 s·∫£n ph·∫©m theo Frequency\n",
    "ax3 = axes[1, 0]\n",
    "top_freq = df.groupby(ITEM_COL)[INVOICE_COL].nunique().nlargest(10)\n",
    "colors_freq = [COLOR_BLUE if i < 3 else COLOR_GREEN for i in range(len(top_freq))]\n",
    "ax3.barh(range(len(top_freq)), top_freq.values, color=colors_freq)\n",
    "ax3.set_yticks(range(len(top_freq)))\n",
    "ax3.set_yticklabels([name[:30] + '...' if len(name) > 30 else name for name in top_freq.index], fontsize=9)\n",
    "ax3.invert_yaxis()\n",
    "ax3.set_title('üî¢ Top 10 S·∫£n ph·∫©m theo Frequency', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('S·ªë l·∫ßn xu·∫•t hi·ªán')\n",
    "\n",
    "# 1.4 So s√°nh t·ªïng quan\n",
    "ax4 = axes[1, 1]\n",
    "metrics = ['T·ªïng Giao d·ªãch', 'S·ªë Ho√° ƒë∆°n', 'S·ªë S·∫£n ph·∫©m', 'T·ªïng Utility (x1000¬£)']\n",
    "values = [\n",
    "    df.shape[0],\n",
    "    df[INVOICE_COL].nunique(),\n",
    "    df[ITEM_COL].nunique(),\n",
    "    total_utility / 1000\n",
    "]\n",
    "colors_bar = [COLOR_BLUE, COLOR_GREEN, COLOR_ORANGE, COLOR_GREEN]\n",
    "bars = ax4.bar(metrics, values, color=colors_bar, edgecolor='white', linewidth=2)\n",
    "ax4.set_title('T·ªïng quan Database', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('S·ªë l∆∞·ª£ng')\n",
    "\n",
    "# Th√™m gi√° tr·ªã tr√™n thanh\n",
    "for bar, val in zip(bars, values):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.02,\n",
    "             f'{val:,.0f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('T·ªîNG QUAN D·ªÆ LI·ªÜU B√ÅN H√ÄNG', fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "# L∆∞u bi·ªÉu ƒë·ªì\n",
    "chart_path = os.path.join(LAB_OUTPUT_DIR, '3.3 Tong Quan Du Lieu.png')\n",
    "plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab46dc1",
   "metadata": {},
   "source": [
    "## 4. Tri·ªÉn khai High-Utility Itemset Mining\n",
    "\n",
    "### 4.1 Class HighUtilityMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighUtilityMiner:\n",
    "    \"\"\"\n",
    "    High-Utility Itemset Mining using TWU-based approach.\n",
    "    \n",
    "    Thu·∫≠t to√°n n√†y s·ª≠ d·ª•ng Transaction-Weighted Utilization (TWU) \n",
    "    l√†m upper bound ƒë·ªÉ c·∫Øt t·ªâa kh√¥ng gian t√¨m ki·∫øm hi·ªáu qu·∫£.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, invoice_col, item_col, quantity_col, utility_col):\n",
    "        \"\"\"\n",
    "        Kh·ªüi t·∫°o HighUtilityMiner.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame ch·ª©a d·ªØ li·ªáu giao d·ªãch\n",
    "            invoice_col: T√™n c·ªôt m√£ ho√° ƒë∆°n\n",
    "            item_col: T√™n c·ªôt s·∫£n ph·∫©m\n",
    "            quantity_col: T√™n c·ªôt s·ªë l∆∞·ª£ng\n",
    "            utility_col: T√™n c·ªôt utility (doanh thu/l·ª£i nhu·∫≠n)\n",
    "        \"\"\"\n",
    "        self.df = df.copy()\n",
    "        self.invoice_col = invoice_col\n",
    "        self.item_col = item_col\n",
    "        self.quantity_col = quantity_col\n",
    "        self.utility_col = utility_col\n",
    "        \n",
    "        # Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "        self._prepare_data()\n",
    "        \n",
    "    def _prepare_data(self):\n",
    "        \"\"\"Chu·∫©n b·ªã d·ªØ li·ªáu cho HUIM.\"\"\"\n",
    "        # T√≠nh utility cho m·ªói item trong m·ªói giao d·ªãch\n",
    "        self.transactions = {}\n",
    "        self.transaction_utilities = {}  # TU(T_k)\n",
    "        self.item_utilities = defaultdict(float)  # T·ªïng utility c·ªßa m·ªói item\n",
    "        self.item_twu = defaultdict(float)  # TWU c·ªßa m·ªói item\n",
    "        \n",
    "        for invoice, group in self.df.groupby(self.invoice_col):\n",
    "            # L∆∞u c√°c item v√† utility trong giao d·ªãch\n",
    "            items_utilities = {}\n",
    "            for _, row in group.iterrows():\n",
    "                item = row[self.item_col]\n",
    "                utility = row[self.utility_col]\n",
    "                items_utilities[item] = items_utilities.get(item, 0) + utility\n",
    "            \n",
    "            self.transactions[invoice] = items_utilities\n",
    "            tu = sum(items_utilities.values())  # Transaction Utility\n",
    "            self.transaction_utilities[invoice] = tu\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t TWU cho m·ªói item\n",
    "            for item in items_utilities:\n",
    "                self.item_twu[item] += tu\n",
    "                self.item_utilities[item] += items_utilities[item]\n",
    "        \n",
    "        self.total_utility = sum(self.transaction_utilities.values())\n",
    "        print(f\"ƒê√£ chu·∫©n b·ªã {len(self.transactions):,} giao d·ªãch\")\n",
    "        print(f\"T·ªïng utility c·ªßa database: ¬£{self.total_utility:,.2f}\")\n",
    "    \n",
    "    def mine_high_utility_itemsets(self, min_utility, max_length=3):\n",
    "        \"\"\"\n",
    "        Khai th√°c High-Utility Itemsets s·ª≠ d·ª•ng TWU pruning.\n",
    "        \n",
    "        Args:\n",
    "            min_utility: Ng∆∞·ª°ng utility t·ªëi thi·ªÉu\n",
    "            max_length: ƒê·ªô d√†i t·ªëi ƒëa c·ªßa itemset\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame ch·ª©a c√°c High-Utility Itemsets\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== Mining High-Utility Itemsets ===\")\n",
    "        print(f\"Min Utility: ¬£{min_utility:,.2f}\")\n",
    "        print(f\"Max Length: {max_length}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # B∆∞·ªõc 1: L·ªçc c√°c item c√≥ TWU >= min_utility\n",
    "        promising_items = [\n",
    "            item for item, twu in self.item_twu.items() \n",
    "            if twu >= min_utility\n",
    "        ]\n",
    "        print(f\"S·ªë item c√≥ TWU >= min_utility: {len(promising_items):,}\")\n",
    "        \n",
    "        # B∆∞·ªõc 2: T√≠nh utility th·ª±c t·∫ø cho 1-itemsets\n",
    "        hui_results = []\n",
    "        \n",
    "        for item in promising_items:\n",
    "            utility = self.item_utilities[item]\n",
    "            if utility >= min_utility:\n",
    "                hui_results.append({\n",
    "                    'itemset': frozenset([item]),\n",
    "                    'utility': utility,\n",
    "                    'length': 1,\n",
    "                    'twu': self.item_twu[item]\n",
    "                })\n",
    "        \n",
    "        print(f\"1-itemsets HUI: {len(hui_results):,}\")\n",
    "        \n",
    "        # B∆∞·ªõc 3: Sinh k-itemsets (k >= 2)\n",
    "        if max_length >= 2:\n",
    "            # T·∫°o itemset TWU map cho vi·ªác generate candidates\n",
    "            for k in range(2, max_length + 1):\n",
    "                k_itemsets = self._generate_k_itemsets(\n",
    "                    promising_items, k, min_utility\n",
    "                )\n",
    "                hui_results.extend(k_itemsets)\n",
    "                print(f\"{k}-itemsets HUI: {len(k_itemsets):,}\")\n",
    "                \n",
    "                if len(k_itemsets) == 0:\n",
    "                    break\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nTh·ªùi gian ch·∫°y: {elapsed:.2f} gi√¢y\")\n",
    "        print(f\"T·ªïng s·ªë High-Utility Itemsets: {len(hui_results):,}\")\n",
    "        \n",
    "        # T·∫°o DataFrame k·∫øt qu·∫£\n",
    "        if hui_results:\n",
    "            df_hui = pd.DataFrame(hui_results)\n",
    "            df_hui['itemset_str'] = df_hui['itemset'].apply(\n",
    "                lambda x: ', '.join(sorted(list(x)))\n",
    "            )\n",
    "            df_hui['utility_percent'] = (df_hui['utility'] / self.total_utility * 100)\n",
    "            df_hui = df_hui.sort_values('utility', ascending=False).reset_index(drop=True)\n",
    "            return df_hui\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def _generate_k_itemsets(self, items, k, min_utility):\n",
    "        \"\"\"\n",
    "        Sinh v√† ƒë√°nh gi√° k-itemsets.\n",
    "        \n",
    "        Args:\n",
    "            items: Danh s√°ch c√°c item ti·ªÅm nƒÉng\n",
    "            k: ƒê·ªô d√†i itemset\n",
    "            min_utility: Ng∆∞·ª°ng utility t·ªëi thi·ªÉu\n",
    "            \n",
    "        Returns:\n",
    "            List c√°c k-itemsets c√≥ utility >= min_utility\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Sinh t·∫•t c·∫£ k-itemsets t·ª´ promising items\n",
    "        for combo in itertools.combinations(sorted(items), k):\n",
    "            itemset = frozenset(combo)\n",
    "            \n",
    "            # T√≠nh TWU c·ªßa itemset\n",
    "            twu = self._calculate_twu(itemset)\n",
    "            \n",
    "            # Pruning: n·∫øu TWU < min_utility, b·ªè qua\n",
    "            if twu < min_utility:\n",
    "                continue\n",
    "            \n",
    "            # T√≠nh utility th·ª±c t·∫ø\n",
    "            utility = self._calculate_utility(itemset)\n",
    "            \n",
    "            if utility >= min_utility:\n",
    "                results.append({\n",
    "                    'itemset': itemset,\n",
    "                    'utility': utility,\n",
    "                    'length': k,\n",
    "                    'twu': twu\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_twu(self, itemset):\n",
    "        \"\"\"T√≠nh Transaction-Weighted Utilization c·ªßa itemset.\"\"\"\n",
    "        twu = 0\n",
    "        for invoice, items_utils in self.transactions.items():\n",
    "            if itemset.issubset(set(items_utils.keys())):\n",
    "                twu += self.transaction_utilities[invoice]\n",
    "        return twu\n",
    "    \n",
    "    def _calculate_utility(self, itemset):\n",
    "        \"\"\"T√≠nh utility th·ª±c t·∫ø c·ªßa itemset.\"\"\"\n",
    "        total_utility = 0\n",
    "        for invoice, items_utils in self.transactions.items():\n",
    "            if itemset.issubset(set(items_utils.keys())):\n",
    "                # C·ªông utility c·ªßa c√°c item trong itemset\n",
    "                for item in itemset:\n",
    "                    total_utility += items_utils.get(item, 0)\n",
    "        return total_utility\n",
    "    \n",
    "    def get_item_statistics(self):\n",
    "        \"\"\"L·∫•y th·ªëng k√™ v·ªÅ utility c·ªßa t·ª´ng item.\"\"\"\n",
    "        stats = []\n",
    "        for item in self.item_utilities:\n",
    "            stats.append({\n",
    "                'item': item,\n",
    "                'utility': self.item_utilities[item],\n",
    "                'twu': self.item_twu[item],\n",
    "                'utility_percent': self.item_utilities[item] / self.total_utility * 100\n",
    "            })\n",
    "        \n",
    "        df_stats = pd.DataFrame(stats)\n",
    "        df_stats = df_stats.sort_values('utility', ascending=False).reset_index(drop=True)\n",
    "        return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbdebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPTreeNode:\n",
    "    \"\"\"\n",
    "    Node trong UP-Tree (Utility Pattern Tree).\n",
    "    \n",
    "    M·ªói node l∆∞u tr·ªØ th√¥ng tin v·ªÅ m·ªôt item trong m·ªôt path,\n",
    "    bao g·ªìm count, utility v√† link ƒë·∫øn c√°c node c√πng item kh√°c.\n",
    "    \"\"\"\n",
    "    def __init__(self, item=None, parent=None):\n",
    "        self.item = item\n",
    "        self.parent = parent\n",
    "        self.children = {}  # {item: UPTreeNode}\n",
    "        self.count = 0  # S·ªë l·∫ßn xu·∫•t hi·ªán\n",
    "        self.node_utility = 0  # T·ªïng utility t·∫°i node n√†y\n",
    "        self.node_link = None  # Link ƒë·∫øn node c√πng item\n",
    "    \n",
    "    def add_child(self, item, utility=0):\n",
    "        \"\"\"\n",
    "        Th√™m child node ho·∫∑c update n·∫øu ƒë√£ t·ªìn t·∫°i.\n",
    "        \n",
    "        Args:\n",
    "            item: Item name\n",
    "            utility: Utility c·ªßa item trong transaction\n",
    "            \n",
    "        Returns:\n",
    "            Child node\n",
    "        \"\"\"\n",
    "        if item in self.children:\n",
    "            child = self.children[item]\n",
    "            child.count += 1\n",
    "            child.node_utility += utility\n",
    "        else:\n",
    "            child = UPTreeNode(item, self)\n",
    "            child.count = 1\n",
    "            child.node_utility = utility\n",
    "            self.children[item] = child\n",
    "        \n",
    "        return child\n",
    "    \n",
    "    def get_path(self):\n",
    "        \"\"\"\n",
    "        L·∫•y ƒë∆∞·ªùng ƒëi t·ª´ root ƒë·∫øn node n√†y.\n",
    "        \n",
    "        Returns:\n",
    "            List of items t·ª´ root ƒë·∫øn node (kh√¥ng bao g·ªìm root)\n",
    "        \"\"\"\n",
    "        path = []\n",
    "        node = self\n",
    "        while node.parent is not None:\n",
    "            path.append(node.item)\n",
    "            node = node.parent\n",
    "        return path[::-1]\n",
    "    \n",
    "    def get_path_utility(self):\n",
    "        \"\"\"\n",
    "        L·∫•y utility c·ªßa path t·ª´ root ƒë·∫øn node n√†y.\n",
    "        \n",
    "        Returns:\n",
    "            Dict {item: utility} cho path\n",
    "        \"\"\"\n",
    "        path_utils = {}\n",
    "        node = self\n",
    "        while node.parent is not None:\n",
    "            if node.item is not None:\n",
    "                path_utils[node.item] = node.node_utility\n",
    "            node = node.parent\n",
    "        return path_utils\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"String representation cho debugging.\"\"\"\n",
    "        return f\"Node(item={self.item}, count={self.count}, utility={self.node_utility:.2f})\"\n",
    "\n",
    "\n",
    "class UPGrowthMiner:\n",
    "    \"\"\"\n",
    "    UP-Growth: Tree-based High-Utility Itemset Mining.\n",
    "    \n",
    "    Thu·∫≠t to√°n s·ª≠ d·ª•ng UP-Tree (Utility Pattern Tree) v√† pattern growth approach\n",
    "    ƒë·ªÉ khai ph√° High-Utility Itemsets hi·ªáu qu·∫£ m√† kh√¥ng c·∫ßn sinh candidates.\n",
    "    \n",
    "    Key features:\n",
    "    - X√¢y d·ª±ng UP-Tree compact t·ª´ database\n",
    "    - Mining recursively qua conditional pattern bases\n",
    "    - Tr√°nh candidate generation (nhanh h∆°n TWU-based)\n",
    "    - S·ª≠ d·ª•ng TWU ƒë·ªÉ pruning early\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, invoice_col, item_col, quantity_col, utility_col):\n",
    "        \"\"\"\n",
    "        Kh·ªüi t·∫°o UPGrowthMiner.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame ch·ª©a d·ªØ li·ªáu giao d·ªãch\n",
    "            invoice_col: T√™n c·ªôt m√£ ho√° ƒë∆°n\n",
    "            item_col: T√™n c·ªôt s·∫£n ph·∫©m\n",
    "            quantity_col: T√™n c·ªôt s·ªë l∆∞·ª£ng\n",
    "            utility_col: T√™n c·ªôt utility (doanh thu/l·ª£i nhu·∫≠n)\n",
    "        \"\"\"\n",
    "        self.df = df.copy()\n",
    "        self.invoice_col = invoice_col\n",
    "        self.item_col = item_col\n",
    "        self.quantity_col = quantity_col\n",
    "        self.utility_col = utility_col\n",
    "        \n",
    "        # Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "        self._prepare_data()\n",
    "        \n",
    "        # Statistics tracking\n",
    "        self.nodes_created = 0\n",
    "        self.trees_built = 0\n",
    "        \n",
    "    def _prepare_data(self):\n",
    "        \"\"\"Chu·∫©n b·ªã d·ªØ li·ªáu cho UP-Growth.\"\"\"\n",
    "        self.transactions = {}\n",
    "        self.transaction_utilities = {}\n",
    "        self.item_utilities = defaultdict(float)\n",
    "        self.item_twu = defaultdict(float)\n",
    "        \n",
    "        for invoice, group in self.df.groupby(self.invoice_col):\n",
    "            items_utilities = {}\n",
    "            for _, row in group.iterrows():\n",
    "                item = row[self.item_col]\n",
    "                utility = row[self.utility_col]\n",
    "                items_utilities[item] = items_utilities.get(item, 0) + utility\n",
    "            \n",
    "            self.transactions[invoice] = items_utilities\n",
    "            \n",
    "            # T√≠nh transaction utility\n",
    "            tu = sum(items_utilities.values())\n",
    "            self.transaction_utilities[invoice] = tu\n",
    "            \n",
    "            # T√≠nh TWU v√† item utilities\n",
    "            for item in items_utilities:\n",
    "                self.item_twu[item] += tu\n",
    "                self.item_utilities[item] += items_utilities[item]\n",
    "        \n",
    "        self.total_utility = sum(self.transaction_utilities.values())\n",
    "        log_progress(f\"UP-Growth: ƒê√£ chu·∫©n b·ªã {len(self.transactions):,} giao d·ªãch\")\n",
    "    \n",
    "    def _build_up_tree(self, transactions_filtered, item_order):\n",
    "        \"\"\"\n",
    "        X√¢y d·ª±ng UP-Tree t·ª´ transactions ƒë√£ filter.\n",
    "        \n",
    "        Args:\n",
    "            transactions_filtered: Dict {invoice: {item: utility}}\n",
    "            item_order: Dict {item: order} ƒë·ªÉ s·∫Øp x·∫øp consistent\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (root, header_table)\n",
    "            - root: UPTreeNode root c·ªßa tree\n",
    "            - header_table: Dict {item: node_list}\n",
    "        \"\"\"\n",
    "        root = UPTreeNode()\n",
    "        header_table = defaultdict(list)\n",
    "        \n",
    "        self.trees_built += 1\n",
    "        \n",
    "        for invoice, items_utils in transactions_filtered.items():\n",
    "            # S·∫Øp x·∫øp items theo order (TWU descending)\n",
    "            sorted_items = sorted(\n",
    "                items_utils.keys(),\n",
    "                key=lambda x: item_order.get(x, float('inf'))\n",
    "            )\n",
    "            \n",
    "            # Insert v√†o tree\n",
    "            current_node = root\n",
    "            for item in sorted_items:\n",
    "                utility = items_utils[item]\n",
    "                \n",
    "                # Add child (t·∫°o m·ªõi ho·∫∑c update)\n",
    "                child = current_node.add_child(item, utility)\n",
    "                \n",
    "                # Th√™m v√†o header table n·∫øu l√† node m·ªõi\n",
    "                if child.count == 1:  # Node m·ªõi t·∫°o\n",
    "                    # Link v·ªõi node c√πng item tr∆∞·ªõc ƒë√≥\n",
    "                    if header_table[item]:\n",
    "                        last_node = header_table[item][-1]\n",
    "                        last_node.node_link = child\n",
    "                    header_table[item].append(child)\n",
    "                    self.nodes_created += 1\n",
    "                \n",
    "                current_node = child\n",
    "        \n",
    "        return root, dict(header_table)\n",
    "    \n",
    "    def mine_high_utility_itemsets(self, min_utility, max_length=3):\n",
    "        \"\"\"\n",
    "        Khai th√°c High-Utility Itemsets s·ª≠ d·ª•ng UP-Growth pattern growth.\n",
    "        \n",
    "        Args:\n",
    "            min_utility: Ng∆∞·ª°ng utility t·ªëi thi·ªÉu\n",
    "            max_length: ƒê·ªô d√†i t·ªëi ƒëa c·ªßa itemset\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame ch·ª©a c√°c High-Utility Itemsets\n",
    "        \"\"\"\n",
    "        log_progress(f\"UP-Growth Mining - Min Utility: ¬£{min_utility:,.2f}, Max Length: {max_length}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Reset statistics\n",
    "        self.nodes_created = 0\n",
    "        self.trees_built = 0\n",
    "        \n",
    "        # B∆∞·ªõc 1: Filter items c√≥ TWU >= min_utility\n",
    "        promising_items = {\n",
    "            item: self.item_twu[item] \n",
    "            for item, twu in self.item_twu.items()\n",
    "            if twu >= min_utility\n",
    "        }\n",
    "        log_progress(f\"UP-Growth: {len(promising_items):,} promising items\")\n",
    "        \n",
    "        # B∆∞·ªõc 2: T·∫°o item order (TWU descending)\n",
    "        item_order = {\n",
    "            item: idx for idx, (item, twu) in \n",
    "            enumerate(sorted(promising_items.items(), \n",
    "                           key=lambda x: x[1], reverse=True))\n",
    "        }\n",
    "        \n",
    "        # B∆∞·ªõc 3: Filter transactions\n",
    "        transactions_filtered = {}\n",
    "        for invoice, items_utils in self.transactions.items():\n",
    "            filtered = {\n",
    "                item: util for item, util in items_utils.items()\n",
    "                if item in promising_items\n",
    "            }\n",
    "            if filtered:\n",
    "                transactions_filtered[invoice] = filtered\n",
    "        \n",
    "        log_progress(f\"UP-Growth: {len(transactions_filtered):,} transactions sau filter\")\n",
    "        \n",
    "        # B∆∞·ªõc 4: X√¢y d·ª±ng Global UP-Tree\n",
    "        root, header_table = self._build_up_tree(transactions_filtered, item_order)\n",
    "        \n",
    "        log_progress(f\"UP-Growth: ƒê√£ t·∫°o {self.nodes_created:,} nodes trong {self.trees_built} tree(s)\")\n",
    "        \n",
    "        # B∆∞·ªõc 5: Mining t·ª´ UP-Tree b·∫±ng pattern growth\n",
    "        hui_results = []\n",
    "        \n",
    "        # Mine v·ªõi m·ªói item trong header table (bottom-up)\n",
    "        items_sorted = sorted(header_table.keys(), \n",
    "                            key=lambda x: item_order[x], reverse=True)\n",
    "        \n",
    "        for item in items_sorted:\n",
    "            # T√≠nh utility c·ªßa single item\n",
    "            utility = self.item_utilities[item]\n",
    "            \n",
    "            if utility >= min_utility:\n",
    "                hui_results.append({\n",
    "                    'itemset': frozenset([item]),\n",
    "                    'utility': utility,\n",
    "                    'length': 1,\n",
    "                    'twu': self.item_twu[item]\n",
    "                })\n",
    "            \n",
    "            # Mine v·ªõi prefix = {item} n·∫øu ch∆∞a ƒë·∫°t max_length\n",
    "            if max_length > 1:\n",
    "                # L·∫•y conditional pattern base\n",
    "                cpb = self._get_conditional_pattern_base(item, header_table[item])\n",
    "                \n",
    "                if cpb:\n",
    "                    # Build conditional UP-Tree\n",
    "                    cond_tree, cond_header = self._build_conditional_tree(\n",
    "                        cpb, min_utility, item_order\n",
    "                    )\n",
    "                    \n",
    "                    # Mine recursively t·ª´ conditional tree\n",
    "                    if cond_header:\n",
    "                        sub_patterns = self._mine_tree_recursive(\n",
    "                            cond_header, min_utility, [item], \n",
    "                            item_order, max_length\n",
    "                        )\n",
    "                        hui_results.extend(sub_patterns)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        log_progress(\n",
    "            f\"UP-Growth: Ho√†n th√†nh trong {elapsed:.2f}s - \"\n",
    "            f\"{len(hui_results):,} HUI, {self.trees_built} conditional trees\", \n",
    "            \"SUCCESS\"\n",
    "        )\n",
    "        \n",
    "        # T·∫°o DataFrame\n",
    "        if hui_results:\n",
    "            df_hui = pd.DataFrame(hui_results)\n",
    "            df_hui['itemset_str'] = df_hui['itemset'].apply(\n",
    "                lambda x: ', '.join(sorted(list(x)))\n",
    "            )\n",
    "            df_hui['utility_percent'] = (df_hui['utility'] / self.total_utility * 100)\n",
    "            df_hui = df_hui.sort_values('utility', ascending=False).reset_index(drop=True)\n",
    "            return df_hui\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def _get_conditional_pattern_base(self, item, node_list):\n",
    "        \"\"\"\n",
    "        L·∫•y conditional pattern base cho m·ªôt item.\n",
    "        \n",
    "        Args:\n",
    "            item: Item c·∫ßn l·∫•y CPB\n",
    "            node_list: List c√°c nodes ch·ª©a item n√†y\n",
    "            \n",
    "        Returns:\n",
    "            List of patterns: [(prefix_items, utility_dict), ...]\n",
    "        \"\"\"\n",
    "        cpb = []\n",
    "        \n",
    "        for node in node_list:\n",
    "            # L·∫•y path t·ª´ root ƒë·∫øn parent c·ªßa node\n",
    "            path = []\n",
    "            path_utils = {}\n",
    "            current = node.parent\n",
    "            \n",
    "            while current.parent is not None:  # Kh√¥ng l·∫•y root\n",
    "                path.append(current.item)\n",
    "                path_utils[current.item] = current.node_utility\n",
    "                current = current.parent\n",
    "            \n",
    "            if path:  # N·∫øu c√≥ prefix\n",
    "                path.reverse()  # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ ƒë√∫ng th·ª© t·ª±\n",
    "                # M·ªói path xu·∫•t hi·ªán node.count l·∫ßn v·ªõi utility = node.node_utility\n",
    "                cpb.append((path, path_utils, node.count, node.node_utility))\n",
    "        \n",
    "        return cpb\n",
    "    \n",
    "    def _build_conditional_tree(self, cpb, min_utility, item_order):\n",
    "        \"\"\"\n",
    "        X√¢y d·ª±ng conditional UP-Tree t·ª´ conditional pattern base.\n",
    "        \n",
    "        Args:\n",
    "            cpb: Conditional pattern base\n",
    "            min_utility: Min utility threshold\n",
    "            item_order: Item ordering\n",
    "            \n",
    "        Returns:\n",
    "            Tuple (root, header_table)\n",
    "        \"\"\"\n",
    "        # T√≠nh TWU cho m·ªói item trong CPB\n",
    "        item_twu_cond = defaultdict(float)\n",
    "        for path, path_utils, count, node_util in cpb:\n",
    "            # TWU = t·ªïng utility c·ªßa transaction ch·ª©a item\n",
    "            transaction_util = sum(path_utils.values()) + node_util\n",
    "            for item in path:\n",
    "                item_twu_cond[item] += transaction_util * count\n",
    "        \n",
    "        # Filter items c√≥ TWU >= min_utility\n",
    "        promising = {\n",
    "            item: twu for item, twu in item_twu_cond.items()\n",
    "            if twu >= min_utility\n",
    "        }\n",
    "        \n",
    "        if not promising:\n",
    "            return None, {}\n",
    "        \n",
    "        # Build conditional tree\n",
    "        root = UPTreeNode()\n",
    "        header_table = defaultdict(list)\n",
    "        \n",
    "        self.trees_built += 1\n",
    "        \n",
    "        for path, path_utils, count, _ in cpb:\n",
    "            # Filter v√† sort items trong path\n",
    "            filtered_path = [\n",
    "                item for item in path \n",
    "                if item in promising\n",
    "            ]\n",
    "            \n",
    "            if not filtered_path:\n",
    "                continue\n",
    "            \n",
    "            # Sort theo order\n",
    "            filtered_path.sort(key=lambda x: item_order.get(x, float('inf')))\n",
    "            \n",
    "            # Insert v√†o tree\n",
    "            current_node = root\n",
    "            for item in filtered_path:\n",
    "                utility = path_utils.get(item, 0) * count\n",
    "                child = current_node.add_child(item, utility)\n",
    "                \n",
    "                if child.count == count:  # Node m·ªõi\n",
    "                    if header_table[item]:\n",
    "                        header_table[item][-1].node_link = child\n",
    "                    header_table[item].append(child)\n",
    "                    self.nodes_created += 1\n",
    "                \n",
    "                current_node = child\n",
    "        \n",
    "        return root, dict(header_table)\n",
    "    \n",
    "    def _mine_tree_recursive(self, header_table, min_utility, prefix, item_order, max_length):\n",
    "        \"\"\"\n",
    "        Mine recursively t·ª´ conditional tree.\n",
    "        \n",
    "        Args:\n",
    "            header_table: Header table c·ªßa conditional tree\n",
    "            min_utility: Min utility threshold\n",
    "            prefix: Prefix itemset hi·ªán t·∫°i\n",
    "            item_order: Item ordering\n",
    "            max_length: Max itemset length\n",
    "            \n",
    "        Returns:\n",
    "            List of HUI patterns\n",
    "        \"\"\"\n",
    "        hui = []\n",
    "        \n",
    "        # N·∫øu ƒë√£ ƒë·∫°t max_length, d·ª´ng\n",
    "        if len(prefix) >= max_length:\n",
    "            return hui\n",
    "        \n",
    "        # Mine v·ªõi m·ªói item (bottom-up theo order)\n",
    "        items_sorted = sorted(header_table.keys(), \n",
    "                            key=lambda x: item_order.get(x, float('inf')), \n",
    "                            reverse=True)\n",
    "        \n",
    "        for item in items_sorted:\n",
    "            # T·∫°o new itemset = prefix + {item}\n",
    "            new_itemset = prefix + [item]\n",
    "            \n",
    "            # T√≠nh utility c·ªßa new_itemset\n",
    "            utility = self._calculate_itemset_utility_from_nodes(\n",
    "                header_table[item], new_itemset\n",
    "            )\n",
    "            \n",
    "            if utility >= min_utility:\n",
    "                hui.append({\n",
    "                    'itemset': frozenset(new_itemset),\n",
    "                    'utility': utility,\n",
    "                    'length': len(new_itemset),\n",
    "                    'twu': 0  # TWU kh√¥ng c·∫ßn thi·∫øt cho k·∫øt qu·∫£ cu·ªëi\n",
    "                })\n",
    "            \n",
    "            # Ti·∫øp t·ª•c mine n·∫øu ch∆∞a ƒë·∫°t max_length\n",
    "            if len(new_itemset) < max_length:\n",
    "                # L·∫•y CPB cho item\n",
    "                cpb = self._get_conditional_pattern_base(item, header_table[item])\n",
    "                \n",
    "                if cpb:\n",
    "                    # Build conditional tree\n",
    "                    cond_tree, cond_header = self._build_conditional_tree(\n",
    "                        cpb, min_utility, item_order\n",
    "                    )\n",
    "                    \n",
    "                    # Mine recursively\n",
    "                    if cond_header:\n",
    "                        sub_hui = self._mine_tree_recursive(\n",
    "                            cond_header, min_utility, new_itemset, \n",
    "                            item_order, max_length\n",
    "                        )\n",
    "                        hui.extend(sub_hui)\n",
    "        \n",
    "        return hui\n",
    "    \n",
    "    def _calculate_itemset_utility_from_nodes(self, node_list, itemset):\n",
    "        \"\"\"\n",
    "        T√≠nh utility c·ªßa itemset t·ª´ node list.\n",
    "        \n",
    "        Simplified: T√≠nh t·ª´ transactions g·ªëc (ch√≠nh x√°c h∆°n).\n",
    "        \"\"\"\n",
    "        utility = 0\n",
    "        itemset_set = set(itemset)\n",
    "        \n",
    "        for invoice, items_utils in self.transactions.items():\n",
    "            if itemset_set.issubset(set(items_utils.keys())):\n",
    "                for item in itemset_set:\n",
    "                    utility += items_utils[item]\n",
    "        \n",
    "        return utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5ec12",
   "metadata": {},
   "source": [
    "### 4.2 Class UPGrowthMiner (UP-Growth Algorithm)\n",
    "\n",
    "UP-Growth l√† thu·∫≠t to√°n c·∫£i ti·∫øn s·ª≠ d·ª•ng c·∫•u tr√∫c c√¢y (tree-based) t∆∞∆°ng t·ª± FP-Growth ƒë·ªÉ khai ph√° High-Utility Itemsets hi·ªáu qu·∫£ h∆°n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e6a35",
   "metadata": {},
   "source": [
    "### 4.3 Khai th√°c High-Utility Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o HighUtilityMiner\n",
    "hui_miner = HighUtilityMiner(\n",
    "    df=df,\n",
    "    invoice_col=INVOICE_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    quantity_col=QUANTITY_COL,\n",
    "    utility_col=TOTAL_COL\n",
    ")\n",
    "\n",
    "log_progress(\n",
    "    f\"HighUtilityMiner initialized: {len(hui_miner.transactions):,} transactions, \"\n",
    "    f\"total utility ¬£{hui_miner.total_utility:,.2f}\",\n",
    "    \"SUCCESS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f385325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o UPGrowthMiner\n",
    "up_miner = UPGrowthMiner(\n",
    "    df=df,\n",
    "    invoice_col=INVOICE_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    quantity_col=QUANTITY_COL,\n",
    "    utility_col=TOTAL_COL\n",
    ")\n",
    "\n",
    "log_progress(\n",
    "    f\"UPGrowthMiner initialized: {len(up_miner.transactions):,} transactions, \"\n",
    "    f\"total utility ¬£{up_miner.total_utility:,.2f}\",\n",
    "    \"SUCCESS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S·ª≠ d·ª•ng tham s·ªë t·ª´ cell Parameters ph√≠a tr√™n\n",
    "test_thresholds = TEST_THRESHOLDS\n",
    "print(f\"\\nüî¨ B·∫Øt ƒë·∫ßu th·ª≠ nghi·ªám v·ªõi {len(test_thresholds)} ng∆∞·ª°ng utility\")\n",
    "print(f\"üìè Max itemset length: {MAX_ITEMSET_LENGTH}\")\n",
    "print(f\"‚è±Ô∏è Timeout: {EXPERIMENT_TIMEOUT}s ({EXPERIMENT_TIMEOUT/60:.1f} min) m·ªói experiment\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√≠nh ng∆∞·ª°ng utility\n",
    "if MIN_UTILITY_ABSOLUTE > 0:\n",
    "    min_utility = MIN_UTILITY_ABSOLUTE\n",
    "else:\n",
    "    min_utility = hui_miner.total_utility * MIN_UTILITY_PERCENT\n",
    "\n",
    "print(f\"Ng∆∞·ª°ng Min Utility: ¬£{min_utility:,.2f}\")\n",
    "print(f\"(T∆∞∆°ng ƒë∆∞∆°ng {min_utility/hui_miner.total_utility*100:.4f}% t·ªïng doanh thu)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e084e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "twu_experiment_results = []\n",
    "\n",
    "for idx, threshold_pct in enumerate(test_thresholds, 1):\n",
    "    try:\n",
    "        log_progress(f\"\\n{'='*60}\", \"INFO\")\n",
    "        log_progress(f\"TWU Experiment {idx}/{len(test_thresholds)}: Threshold = {threshold_pct*100}%\", \"INFO\")\n",
    "        log_progress(f\"‚è±Ô∏è Timeout: {EXPERIMENT_TIMEOUT}s ({EXPERIMENT_TIMEOUT/60:.1f} min)\", \"INFO\")\n",
    "        log_progress(f\"{'='*60}\", \"INFO\")\n",
    "        \n",
    "        # T√≠nh min_utility\n",
    "        min_util = hui_miner.total_utility * threshold_pct\n",
    "        log_progress(f\"Min Utility: ¬£{min_util:,.2f}\", \"INFO\")\n",
    "        \n",
    "        # Wrapper function v·ªõi timeout\n",
    "        def run_mining_with_timeout():\n",
    "            return hui_miner.mine_high_utility_itemsets(\n",
    "                min_utility=min_util,\n",
    "                max_length=MAX_ITEMSET_LENGTH\n",
    "            )\n",
    "        \n",
    "        # Apply timeout decorator\n",
    "        mining_func = timeout_decorator(EXPERIMENT_TIMEOUT)(run_mining_with_timeout)\n",
    "        \n",
    "        # Ch·∫°y mining v·ªõi timeout protection\n",
    "        start_time = time.time()\n",
    "        df_hui_test = mining_func()\n",
    "        runtime = time.time() - start_time\n",
    "        \n",
    "        # Thu th·∫≠p k·∫øt qu·∫£\n",
    "        n_itemsets = len(df_hui_test) if not df_hui_test.empty else 0\n",
    "        n_1itemsets = len(df_hui_test[df_hui_test['length']==1]) if not df_hui_test.empty else 0\n",
    "        n_2itemsets = len(df_hui_test[df_hui_test['length']==2]) if not df_hui_test.empty else 0\n",
    "        n_3itemsets = len(df_hui_test[df_hui_test['length']==3]) if not df_hui_test.empty else 0\n",
    "        \n",
    "        max_utility = df_hui_test['utility'].max() if not df_hui_test.empty else 0\n",
    "        avg_utility = df_hui_test['utility'].mean() if not df_hui_test.empty else 0\n",
    "        \n",
    "        result = {\n",
    "            'algorithm': 'TWU-based',\n",
    "            'min_utility_percent': threshold_pct,\n",
    "            'min_utility_value': min_util,\n",
    "            'runtime_sec': runtime,\n",
    "            'n_itemsets': n_itemsets,\n",
    "            'n_1itemsets': n_1itemsets,\n",
    "            'n_2itemsets': n_2itemsets,\n",
    "            'n_3itemsets': n_3itemsets,\n",
    "            'max_utility': max_utility,\n",
    "            'avg_utility': avg_utility,\n",
    "            'timeout': False,\n",
    "            'status': 'completed',\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        twu_experiment_results.append(result)\n",
    "        \n",
    "        log_progress(f\"‚úì K·∫øt qu·∫£: {n_itemsets} itemsets, Runtime: {runtime:.2f}s\", \"SUCCESS\")\n",
    "    \n",
    "    except TimeoutError as e:\n",
    "        log_progress(f\"‚è±Ô∏è TIMEOUT sau {EXPERIMENT_TIMEOUT}s cho threshold {threshold_pct*100}%\", \"TIMEOUT\")\n",
    "        log_progress(f\"Skipping experiment v√† ti·∫øp t·ª•c v·ªõi threshold ti·∫øp theo...\", \"WARNING\")\n",
    "        \n",
    "        # L∆∞u k·∫øt qu·∫£ timeout\n",
    "        result = {\n",
    "            'algorithm': 'TWU-based',\n",
    "            'min_utility_percent': threshold_pct,\n",
    "            'min_utility_value': hui_miner.total_utility * threshold_pct,\n",
    "            'runtime_sec': EXPERIMENT_TIMEOUT,\n",
    "            'n_itemsets': -1,  # -1 indicates timeout\n",
    "            'n_1itemsets': -1,\n",
    "            'n_2itemsets': -1,\n",
    "            'n_3itemsets': -1,\n",
    "            'max_utility': 0,\n",
    "            'avg_utility': 0,\n",
    "            'timeout': True,\n",
    "            'status': 'timeout',\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        twu_experiment_results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_progress(f\"‚úó L·ªói khi ch·∫°y threshold {threshold_pct*100}%: {str(e)}\", \"ERROR\")\n",
    "        log_progress(traceback.format_exc(), \"ERROR\")\n",
    "        \n",
    "        # L∆∞u k·∫øt qu·∫£ l·ªói\n",
    "        result = {\n",
    "            'algorithm': 'TWU-based',\n",
    "            'min_utility_percent': threshold_pct,\n",
    "            'min_utility_value': hui_miner.total_utility * threshold_pct,\n",
    "            'runtime_sec': 0,\n",
    "            'n_itemsets': -2,  # -2 indicates error\n",
    "            'n_1itemsets': -2,\n",
    "            'n_2itemsets': -2,\n",
    "            'n_3itemsets': -2,\n",
    "            'max_utility': 0,\n",
    "            'avg_utility': 0,\n",
    "            'timeout': False,\n",
    "            'status': f'error: {str(e)}',\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        twu_experiment_results.append(result)\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "df_twu_results = pd.DataFrame(twu_experiment_results)\n",
    "twu_csv_path = os.path.join(LAB_OUTPUT_DIR, 'KetQuaThuNghiem_TapGiaTri_MinUtilityPercent.csv')\n",
    "df_twu_results.to_csv(twu_csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "log_progress(f\"\\n‚úì ƒê√£ l∆∞u k·∫øt qu·∫£ TWU v√†o: {twu_csv_path}\", \"SUCCESS\")\n",
    "print(\"\\nK·∫øt qu·∫£ TWU-based:\")\n",
    "df_twu_results[['min_utility_percent', 'runtime_sec', 'n_itemsets', 'n_1itemsets', 'n_2itemsets', 'n_3itemsets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e30a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "upgrowth_experiment_results = []\n",
    "\n",
    "for idx, threshold_pct in enumerate(test_thresholds, 1):\n",
    "    try:\n",
    "        log_progress(f\"\\n{'='*60}\", \"INFO\")\n",
    "        log_progress(f\"UP-Growth Experiment {idx}/{len(test_thresholds)}: Threshold = {threshold_pct*100}%\", \"INFO\")\n",
    "        log_progress(f\"‚è±Ô∏è Timeout: {EXPERIMENT_TIMEOUT}s ({EXPERIMENT_TIMEOUT/60:.1f} min)\", \"INFO\")\n",
    "        log_progress(f\"{'='*60}\", \"INFO\")\n",
    "        \n",
    "        # T√≠nh min_utility\n",
    "        min_util = up_miner.total_utility * threshold_pct\n",
    "        log_progress(f\"Min Utility: ¬£{min_util:,.2f}\", \"INFO\")\n",
    "        \n",
    "        # Wrapper function v·ªõi timeout\n",
    "        def run_mining_with_timeout():\n",
    "            return up_miner.mine_high_utility_itemsets(\n",
    "                min_utility=min_util,\n",
    "                max_length=MAX_ITEMSET_LENGTH\n",
    "            )\n",
    "        \n",
    "        # Apply timeout decorator\n",
    "        mining_func = timeout_decorator(EXPERIMENT_TIMEOUT)(run_mining_with_timeout)\n",
    "        \n",
    "        # Ch·∫°y mining v·ªõi timeout protection\n",
    "        start_time = time.time()\n",
    "        df_hui_test = mining_func()\n",
    "        runtime = time.time() - start_time\n",
    "        \n",
    "        # Thu th·∫≠p k·∫øt qu·∫£\n",
    "        n_itemsets = len(df_hui_test) if not df_hui_test.empty else 0\n",
    "        n_1itemsets = len(df_hui_test[df_hui_test['length']==1]) if not df_hui_test.empty else 0\n",
    "        n_2itemsets = len(df_hui_test[df_hui_test['length']==2]) if not df_hui_test.empty else 0\n",
    "        n_3itemsets = len(df_hui_test[df_hui_test['length']==3]) if not df_hui_test.empty else 0\n",
    "        \n",
    "        max_utility = df_hui_test['utility'].max() if not df_hui_test.empty else 0\n",
    "        avg_utility = df_hui_test['utility'].mean() if not df_hui_test.empty else 0\n",
    "        \n",
    "        result = {\n",
    "            'algorithm': 'UP-Growth',\n",
    "            'min_utility_percent': threshold_pct,\n",
    "            'min_utility_value': min_util,\n",
    "            'runtime_sec': runtime,\n",
    "            'n_itemsets': n_itemsets,\n",
    "            'n_1itemsets': n_1itemsets,\n",
    "            'n_2itemsets': n_2itemsets,\n",
    "            'n_3itemsets': n_3itemsets,\n",
    "            'max_utility': max_utility,\n",
    "            'avg_utility': avg_utility,\n",
    "            'timeout': False,\n",
    "            'status': 'completed',\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        upgrowth_experiment_results.append(result)\n",
    "        \n",
    "        log_progress(f\"‚úì K·∫øt qu·∫£: {n_itemsets} itemsets, Runtime: {runtime:.2f}s\", \"SUCCESS\")\n",
    "    \n",
    "    except TimeoutError as e:\n",
    "        log_progress(f\"‚è±Ô∏è TIMEOUT sau {EXPERIMENT_TIMEOUT}s cho threshold {threshold_pct*100}%\", \"TIMEOUT\")\n",
    "        log_progress(f\"Skipping experiment v√† ti·∫øp t·ª•c v·ªõi threshold ti·∫øp theo...\", \"WARNING\")\n",
    "        \n",
    "        # L∆∞u k·∫øt qu·∫£ timeout\n",
    "        result = {\n",
    "            'algorithm': 'UP-Growth',\n",
    "            'min_utility_percent': threshold_pct,\n",
    "            'min_utility_value': up_miner.total_utility * threshold_pct,\n",
    "            'runtime_sec': EXPERIMENT_TIMEOUT,\n",
    "            'n_itemsets': -1,  # -1 indicates timeout\n",
    "            'n_1itemsets': -1,\n",
    "            'n_2itemsets': -1,\n",
    "            'n_3itemsets': -1,\n",
    "            'max_utility': 0,\n",
    "            'avg_utility': 0,\n",
    "            'timeout': True,\n",
    "            'status': 'timeout',\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        upgrowth_experiment_results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_progress(f\"‚úó L·ªói khi ch·∫°y threshold {threshold_pct*100}%: {str(e)}\", \"ERROR\")\n",
    "        log_progress(traceback.format_exc(), \"ERROR\")\n",
    "        \n",
    "        # L∆∞u k·∫øt qu·∫£ l·ªói\n",
    "        result = {\n",
    "            'algorithm': 'UP-Growth',\n",
    "            'min_utility_percent': threshold_pct,\n",
    "            'min_utility_value': up_miner.total_utility * threshold_pct,\n",
    "            'runtime_sec': 0,\n",
    "            'n_itemsets': -2,  # -2 indicates error\n",
    "            'n_1itemsets': -2,\n",
    "            'n_2itemsets': -2,\n",
    "            'n_3itemsets': -2,\n",
    "            'max_utility': 0,\n",
    "            'avg_utility': 0,\n",
    "            'timeout': False,\n",
    "            'status': f'error: {str(e)}',\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        upgrowth_experiment_results.append(result)\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "df_upgrowth_results = pd.DataFrame(upgrowth_experiment_results)\n",
    "upgrowth_csv_path = os.path.join(LAB_OUTPUT_DIR, 'KetQuaThuNghiem_UPGrowth_MinUtilityPercent.csv')\n",
    "df_upgrowth_results.to_csv(upgrowth_csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "log_progress(f\"\\n‚úì ƒê√£ l∆∞u k·∫øt qu·∫£ UP-Growth v√†o: {upgrowth_csv_path}\", \"SUCCESS\")\n",
    "print(\"\\nK·∫øt qu·∫£ UP-Growth:\")\n",
    "df_upgrowth_results[['min_utility_percent', 'runtime_sec', 'n_itemsets', 'n_1itemsets', 'n_2itemsets', 'n_3itemsets']]\n",
    "\n",
    "# T·∫°o df_hui cho ph·∫ßn tr·ª±c quan h√≥a ·ªü Section 6\n",
    "# S·ª≠ d·ª•ng ng∆∞·ª°ng MIN_UTILITY_PERCENT m·∫∑c ƒë·ªãnh\n",
    "df_hui = hui_miner.mine_high_utility_itemsets(\n",
    "    min_utility=hui_miner.total_utility * MIN_UTILITY_PERCENT,\n",
    "    max_length=MAX_ITEMSET_LENGTH\n",
    ")\n",
    "log_progress(f\"\\n‚úì T·∫°o df_hui cho visualization: {len(df_hui)} itemsets\", \"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV results for visualization\n",
    "twu_csv_path = os.path.join(LAB_OUTPUT_DIR, 'KetQuaThuNghiem_TapGiaTri_MinUtilityPercent.csv')\n",
    "upgrowth_csv_path = os.path.join(LAB_OUTPUT_DIR, 'KetQuaThuNghiem_UPGrowth_MinUtilityPercent.csv')\n",
    "\n",
    "df_twu_viz = pd.read_csv(twu_csv_path)\n",
    "df_upgrowth_viz = pd.read_csv(upgrowth_csv_path)\n",
    "\n",
    "# Combine both results for comparison\n",
    "df_combined = pd.concat([df_twu_viz, df_upgrowth_viz], ignore_index=True)\n",
    "\n",
    "log_progress(f\"Loaded {len(df_twu_viz)} TWU results and {len(df_upgrowth_viz)} UP-Growth results\", \"SUCCESS\")\n",
    "print(f\"\\nCombined dataframe shape: {df_combined.shape}\")\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bbb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Line chart - Runtime vs Threshold\n",
    "for algo in df_combined['algorithm'].unique():\n",
    "    df_algo = df_combined[df_combined['algorithm'] == algo]\n",
    "    color = COLOR_BLUE if algo == 'TWU-based' else COLOR_GREEN\n",
    "    ax1.plot(df_algo['min_utility_percent'] * 100, df_algo['runtime_sec'], \n",
    "             marker='o', linewidth=2.5, markersize=10, label=algo, color=color)\n",
    "\n",
    "ax1.set_xlabel('Min Utility Threshold (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Runtime (seconds)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('So S√°nh Th·ªùi Gian Ch·∫°y', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Ch·ªâ d√πng log scale n·∫øu c√≥ nhi·ªÅu h∆°n 1 threshold v√† gi√° tr·ªã > 0\n",
    "if len(test_thresholds) > 1 and df_combined['min_utility_percent'].min() > 0:\n",
    "    ax1.set_xscale('log')\n",
    "\n",
    "# Plot 2: Bar chart - Runtime comparison\n",
    "x_pos = np.arange(len(test_thresholds))\n",
    "width = 0.35\n",
    "\n",
    "twu_runtimes = df_twu_viz['runtime_sec'].values\n",
    "up_runtimes = df_upgrowth_viz['runtime_sec'].values\n",
    "\n",
    "bars1 = ax2.bar(x_pos - width/2, twu_runtimes, width, label='TWU-based', \n",
    "                color=COLOR_BLUE, edgecolor='white', linewidth=1.5)\n",
    "bars2 = ax2.bar(x_pos + width/2, up_runtimes, width, label='UP-Growth', \n",
    "                color=COLOR_GREEN, edgecolor='white', linewidth=1.5)\n",
    "\n",
    "ax2.set_xlabel('Min Utility Threshold', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Runtime (seconds)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Runtime So S√°nh Theo Threshold', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([f'{t*100}%' for t in test_thresholds])\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Th√™m gi√° tr·ªã tr√™n thanh\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}s', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# L∆∞u bi·ªÉu ƒë·ªì\n",
    "chart_path = os.path.join(LAB_OUTPUT_DIR, '5.1 So Sanh Thoi Gian Chay.png')\n",
    "plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "plt.show()\n",
    "\n",
    "# T√≠nh speedup\n",
    "log_progress(\"\\n\" + \"=\"*60, \"INFO\")\n",
    "log_progress(\"PH√ÇN T√çCH SPEEDUP (TWU-based vs UP-Growth)\", \"INFO\")\n",
    "log_progress(\"=\"*60, \"INFO\")\n",
    "for i, threshold in enumerate(test_thresholds):\n",
    "    if up_runtimes[i] > 0:\n",
    "        speedup = twu_runtimes[i] / up_runtimes[i]\n",
    "        faster = \"UP-Growth\" if speedup > 1 else \"TWU-based\"\n",
    "        log_progress(f\"Threshold {threshold*100}%: {faster} nhanh h∆°n {abs(speedup):.2f}x\", \"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Ki·ªÉm tra n·∫øu t·∫•t c·∫£ itemsets = 0\n",
    "if df_combined['n_itemsets'].max() == 0:\n",
    "    print(\"‚ö†Ô∏è Kh√¥ng c√≥ High-Utility Itemsets n√†o ƒë∆∞·ª£c t√¨m th·∫•y ·ªü c√°c threshold ƒë√£ test.\")\n",
    "    print(\"üí° Khuy·∫øn ngh·ªã: Gi·∫£m threshold ƒë·ªÉ t√¨m ƒë∆∞·ª£c itemsets.\")\n",
    "    \n",
    "    # V·∫Ω bi·ªÉu ƒë·ªì th√¥ng b√°o\n",
    "    plt.text(0.5, 0.5, 'Kh√¥ng c√≥ HUI n√†o ƒë∆∞·ª£c t√¨m th·∫•y\\n\\nThreshold qu√° cao!\\nH√£y gi·∫£m MIN_UTILITY_PERCENT', \n",
    "             ha='center', va='center', fontsize=14, \n",
    "             transform=plt.gca().transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    plt.xlabel('S·ªë l∆∞·ª£ng High-Utility Itemsets', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Runtime (seconds)', fontsize=12, fontweight='bold')\n",
    "    plt.title('Runtime vs S·ªë L∆∞·ª£ng Itemsets (colored by Algorithm)', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    for algo in df_combined['algorithm'].unique():\n",
    "        df_algo = df_combined[df_combined['algorithm'] == algo]\n",
    "        color = COLOR_BLUE if algo == 'TWU-based' else COLOR_GREEN\n",
    "        \n",
    "        plt.scatter(df_algo['n_itemsets'], df_algo['runtime_sec'], \n",
    "                    s=300, alpha=0.7, color=color, edgecolors='white', linewidth=2,\n",
    "                    label=algo)\n",
    "        \n",
    "        # Th√™m labels cho m·ªói ƒëi·ªÉm\n",
    "        for _, row in df_algo.iterrows():\n",
    "            plt.annotate(f\"{row['min_utility_percent']*100}%\",\n",
    "                        (row['n_itemsets'], row['runtime_sec']),\n",
    "                        textcoords=\"offset points\", xytext=(0,10),\n",
    "                        ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "    plt.xlabel('S·ªë l∆∞·ª£ng High-Utility Itemsets', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Runtime (seconds)', fontsize=12, fontweight='bold')\n",
    "    plt.title('Runtime vs S·ªë L∆∞·ª£ng Itemsets (colored by Algorithm)', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=11, loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if df_combined['n_itemsets'].min() > 0:\n",
    "        plt.xscale('log')\n",
    "    if df_combined['runtime_sec'].min() > 0:\n",
    "        plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# L∆∞u bi·ªÉu ƒë·ªì\n",
    "chart_path = os.path.join(LAB_OUTPUT_DIR, '5.1 Runtime vs So Luong Itemsets.png')\n",
    "plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_progress(\"\\n\" + \"=\"*80, \"INFO\")\n",
    "log_progress(\"K·∫æT LU·∫¨N T·ª™ TH·ª¨ NGHI·ªÜM\", \"INFO\")\n",
    "log_progress(\"=\"*80, \"INFO\")\n",
    "\n",
    "# 1. Ph√¢n t√≠ch threshold\n",
    "log_progress(\"\\n1. PH√ÇN T√çCH THRESHOLD:\", \"INFO\")\n",
    "for i, threshold in enumerate(test_thresholds):\n",
    "    n_items = df_twu_viz.iloc[i]['n_itemsets']\n",
    "    log_progress(f\"   - Threshold {threshold*100}%: T√¨m ƒë∆∞·ª£c {int(n_items)} itemsets\", \"INFO\")\n",
    "\n",
    "# 2. So s√°nh thu·∫≠t to√°n\n",
    "log_progress(\"\\n2. SO S√ÅNH THU·∫¨T TO√ÅN:\", \"INFO\")\n",
    "avg_twu_runtime = df_twu_viz['runtime_sec'].mean()\n",
    "avg_up_runtime = df_upgrowth_viz['runtime_sec'].mean()\n",
    "overall_speedup = avg_twu_runtime / avg_up_runtime if avg_up_runtime > 0 else 0\n",
    "\n",
    "if overall_speedup > 1:\n",
    "    log_progress(f\"   - UP-Growth nhanh h∆°n trung b√¨nh {overall_speedup:.2f}x\", \"SUCCESS\")\n",
    "else:\n",
    "    log_progress(f\"   - TWU-based nhanh h∆°n trung b√¨nh {1/overall_speedup:.2f}x\", \"SUCCESS\")\n",
    "\n",
    "# 3. Khuy·∫øn ngh·ªã\n",
    "log_progress(\"\\n3. KHUY·∫æN NGH·ªä:\", \"INFO\")\n",
    "best_threshold = None\n",
    "for i, threshold in enumerate(test_thresholds):\n",
    "    n_items = df_twu_viz.iloc[i]['n_itemsets']\n",
    "    if 20 <= n_items <= 100:  # Sweet spot\n",
    "        best_threshold = threshold\n",
    "        log_progress(f\"   ‚úì Ng∆∞·ª°ng t·ªëi ∆∞u: {threshold*100}% (t√¨m ƒë∆∞·ª£c {int(n_items)} itemsets)\", \"SUCCESS\")\n",
    "        break\n",
    "\n",
    "if not best_threshold:\n",
    "    log_progress(f\"   - Th·ª≠ nghi·ªám threshold th·∫•p h∆°n 1.25% ƒë·ªÉ t√¨m nhi·ªÅu itemsets h∆°n\", \"WARNING\")\n",
    "\n",
    "log_progress(\"\\n\" + \"=\"*80, \"INFO\")\n",
    "log_progress(\"‚úì HO√ÄN TH√ÄNH T·∫§T C·∫¢ TH·ª¨ NGHI·ªÜM\", \"SUCCESS\")\n",
    "log_progress(\"=\"*80, \"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006352bc",
   "metadata": {},
   "source": [
    "## 5. K·∫øt Lu·∫≠n T·ª´ Th·ª≠ Nghi·ªám\n",
    "\n",
    "Ph·∫ßn n√†y t·ªïng h·ª£p v√† tr·ª±c quan h√≥a k·∫øt qu·∫£ t·ª´ c√°c th·ª≠ nghi·ªám HUIM ƒë√£ ch·∫°y ·ªü Section 4.\n",
    "\n",
    "### Insights t·ª´ k·∫øt qu·∫£ th·ª≠ nghi·ªám:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3dc94",
   "metadata": {},
   "source": [
    "### 5.1 ƒê·ªçc K·∫øt Qu·∫£ T·ª´ CSV\n",
    "\n",
    "ƒê·ªçc k·∫øt qu·∫£ th·ª≠ nghi·ªám ƒë√£ l∆∞u t·ª´ c√°c file CSV ƒë·ªÉ ph·ª•c v·ª• tr·ª±c quan h√≥a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªçc k·∫øt qu·∫£ t·ª´ CSV files\n",
    "twu_csv_path = os.path.join(LAB_OUTPUT_DIR, 'KetQuaThuNghiem_TapGiaTri_MinUtilityPercent.csv')\n",
    "upgrowth_csv_path = os.path.join(LAB_OUTPUT_DIR, 'KetQuaThuNghiem_UPGrowth_MinUtilityPercent.csv')\n",
    "\n",
    "# Ki·ªÉm tra file t·ªìn t·∫°i\n",
    "if not os.path.exists(twu_csv_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File TWU kh√¥ng t·ªìn t·∫°i: {twu_csv_path}\\n\"\n",
    "                           f\"‚Üí Ch·∫°y l·∫°i experiments ·ªü Section 4.3 tr∆∞·ªõc!\")\n",
    "\n",
    "if not os.path.exists(upgrowth_csv_path):\n",
    "    raise FileNotFoundError(f\"‚ùå File UP-Growth kh√¥ng t·ªìn t·∫°i: {upgrowth_csv_path}\\n\"\n",
    "                           f\"‚Üí Ch·∫°y l·∫°i experiments ·ªü Section 4.3 tr∆∞·ªõc!\")\n",
    "\n",
    "# ƒê·ªçc CSV\n",
    "df_twu_viz = pd.read_csv(twu_csv_path)\n",
    "df_upgrowth_viz = pd.read_csv(upgrowth_csv_path)\n",
    "\n",
    "# K·∫øt h·ª£p 2 datasets\n",
    "df_combined = pd.concat([df_twu_viz, df_upgrowth_viz], ignore_index=True)\n",
    "\n",
    "log_progress(f\"ƒê√£ ƒë·ªçc {len(df_twu_viz)} k·∫øt qu·∫£ TWU v√† {len(df_upgrowth_viz)} k·∫øt qu·∫£ UP-Growth\", \"INFO\")\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d354a4d0",
   "metadata": {},
   "source": [
    "### 5.2 B·∫£ng T·ªïng H·ª£p K·∫øt Qu·∫£\n",
    "\n",
    "T·∫°o b·∫£ng t·ªïng h·ª£p so s√°nh hi·ªáu su·∫•t gi·ªØa TWU-based v√† UP-Growth ·ªü c√°c ng∆∞·ª°ng kh√°c nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf77b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o b·∫£ng t·ªïng h·ª£p\n",
    "summary_data = []\n",
    "\n",
    "for threshold in test_thresholds:\n",
    "    twu_row = df_twu_viz[df_twu_viz['min_utility_percent'] == threshold].iloc[0]\n",
    "    up_row = df_upgrowth_viz[df_upgrowth_viz['min_utility_percent'] == threshold].iloc[0]\n",
    "    \n",
    "    speedup = twu_row['runtime_sec'] / up_row['runtime_sec'] if up_row['runtime_sec'] > 0 else 0\n",
    "    faster_algo = 'UP-Growth' if speedup > 1 else 'TWU-based'\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Threshold (%)': f\"{threshold*100}%\",\n",
    "        'TWU Runtime (s)': f\"{twu_row['runtime_sec']:.2f}\",\n",
    "        'UP Runtime (s)': f\"{up_row['runtime_sec']:.2f}\",\n",
    "        'Speedup': f\"{abs(speedup):.2f}x\",\n",
    "        'Faster': faster_algo,\n",
    "        'TWU Itemsets': int(twu_row['n_itemsets']),\n",
    "        'UP Itemsets': int(up_row['n_itemsets']),\n",
    "        'Match': '‚úì' if twu_row['n_itemsets'] == up_row['n_itemsets'] else '‚úó'\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä B·∫¢NG T·ªîNG H·ª¢P K·∫æT QU·∫¢ TH·ª¨ NGHI·ªÜM\")\n",
    "print(\"=\"*100)\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# L∆∞u b·∫£ng t·ªïng h·ª£p\n",
    "summary_path = os.path.join(LAB_OUTPUT_DIR, 'TongHop_SoSanh_TWU_UPGrowth.csv')\n",
    "df_summary.to_csv(summary_path, index=False, encoding='utf-8-sig')\n",
    "log_progress(f\"\\n‚úì ƒê√£ l∆∞u b·∫£ng t·ªïng h·ª£p v√†o: {summary_path}\", \"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad51c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.3 Bi·ªÉu ƒê·ªì So S√°nh S·ªë L∆∞·ª£ng Itemsets\n",
    "# Tr·ª±c quan h√≥a s·ªë l∆∞·ª£ng High-Utility Itemsets t√¨m ƒë∆∞·ª£c v√† ph√¢n b·ªë theo ƒë·ªô d√†i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Total itemsets comparison\n",
    "for algo in df_combined['algorithm'].unique():\n",
    "    df_algo = df_combined[df_combined['algorithm'] == algo]\n",
    "    color = COLOR_BLUE if algo == 'TWU-based' else COLOR_GREEN\n",
    "    ax1.plot(df_algo['min_utility_percent'] * 100, df_algo['n_itemsets'], \n",
    "             marker='s', linewidth=2.5, markersize=10, label=algo, color=color)\n",
    "\n",
    "ax1.set_xlabel('Min Utility Threshold (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('S·ªë l∆∞·ª£ng High-Utility Itemsets', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('S·ªë L∆∞·ª£ng HUI T√¨m ƒê∆∞·ª£c', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Ch·ªâ d√πng log scale n·∫øu c√≥ d·ªØ li·ªáu > 0\n",
    "if df_combined['n_itemsets'].min() > 0:\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "elif df_combined['n_itemsets'].max() == 0:\n",
    "    ax1.text(0.5, 0.5, 'Kh√¥ng c√≥ HUI\\n(Threshold qu√° cao)', \n",
    "             ha='center', va='center', fontsize=12, \n",
    "             transform=ax1.transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Plot 2: Stacked bar - Distribution by length\n",
    "x_pos = np.arange(len(test_thresholds))\n",
    "width = 0.35\n",
    "\n",
    "# TWU-based stacked bars\n",
    "twu_1 = df_twu_viz['n_1itemsets'].values\n",
    "twu_2 = df_twu_viz['n_2itemsets'].values\n",
    "twu_3 = df_twu_viz['n_3itemsets'].values\n",
    "\n",
    "ax2.bar(x_pos - width/2, twu_1, width, label='1-itemsets', \n",
    "        color=COLOR_BLUE, edgecolor='white', linewidth=1.5)\n",
    "ax2.bar(x_pos - width/2, twu_2, width, bottom=twu_1, label='2-itemsets', \n",
    "        color=COLOR_GREEN, edgecolor='white', linewidth=1.5)\n",
    "ax2.bar(x_pos - width/2, twu_3, width, bottom=twu_1+twu_2, label='3-itemsets', \n",
    "        color=COLOR_ORANGE, edgecolor='white', linewidth=1.5)\n",
    "\n",
    "# UP-Growth stacked bars\n",
    "up_1 = df_upgrowth_viz['n_1itemsets'].values\n",
    "up_2 = df_upgrowth_viz['n_2itemsets'].values\n",
    "up_3 = df_upgrowth_viz['n_3itemsets'].values\n",
    "\n",
    "ax2.bar(x_pos + width/2, up_1, width, \n",
    "        color=COLOR_BLUE, edgecolor='white', linewidth=1.5, alpha=0.7)\n",
    "ax2.bar(x_pos + width/2, up_2, width, bottom=up_1, \n",
    "        color=COLOR_GREEN, edgecolor='white', linewidth=1.5, alpha=0.7)\n",
    "ax2.bar(x_pos + width/2, up_3, width, bottom=up_1+up_2, \n",
    "        color=COLOR_ORANGE, edgecolor='white', linewidth=1.5, alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel('Min Utility Threshold', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('S·ªë l∆∞·ª£ng Itemsets', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Ph√¢n B·ªë Itemsets Theo ƒê·ªô D√†i (TWU-left, UP-right)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([f'{t*100}%' for t in test_thresholds])\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# L∆∞u bi·ªÉu ƒë·ªì\n",
    "chart_path = os.path.join(LAB_OUTPUT_DIR, '5.3 So Sanh So Luong Itemsets.png')\n",
    "plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3712e4",
   "metadata": {},
   "source": [
    "## 6. Ph√¢n T√≠ch B·ªï Sung\n",
    "\n",
    "Ph√¢n t√≠ch chi ti·∫øt h∆°n v·ªÅ m·ªëi quan h·ªá gi·ªØa Utility v√† Frequency c·ªßa c√°c items, ƒë·ªìng th·ªùi t√¨m ki·∫øm nh·ªØng \"Hidden Gems\" - s·∫£n ph·∫©m c√≥ gi√° tr·ªã cao nh∆∞ng √≠t ƒë∆∞·ª£c ch√∫ √Ω."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d09975",
   "metadata": {},
   "source": [
    "### 6.1 Th·ªëng K√™ Utility Theo Item\n",
    "\n",
    "Ph√¢n t√≠ch th·ªëng k√™ utility c·ªßa t·ª´ng item ƒë·ªÉ hi·ªÉu s·ª± ph√¢n b·ªë gi√° tr·ªã trong dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3800602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y th·ªëng k√™ item\n",
    "df_item_stats = hui_miner.get_item_statistics()\n",
    "\n",
    "print(\"=== Top 20 Items theo Utility ===\")\n",
    "print(df_item_stats.head(20).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So s√°nh v·ªõi Frequency\n",
    "# T√≠nh frequency c·ªßa m·ªói item\n",
    "item_freq = df.groupby(ITEM_COL)[INVOICE_COL].nunique().reset_index()\n",
    "item_freq.columns = ['item', 'frequency']\n",
    "item_freq['frequency_percent'] = item_freq['frequency'] / df[INVOICE_COL].nunique() * 100\n",
    "\n",
    "# Merge v·ªõi utility stats\n",
    "df_comparison = df_item_stats.merge(item_freq, on='item', how='left')\n",
    "df_comparison = df_comparison.sort_values('utility', ascending=False)\n",
    "\n",
    "print(\"\\n=== So s√°nh Utility vs Frequency (Top 20 theo Utility) ===\")\n",
    "print(df_comparison[['item', 'utility', 'utility_percent', 'frequency', 'frequency_percent']].head(20).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac42cf",
   "metadata": {},
   "source": [
    "### 6.2 Tr·ª±c Quan H√≥a Utility vs Frequency\n",
    "\n",
    "So s√°nh tr·ª±c quan gi·ªØa Utility v√† Frequency ƒë·ªÉ ph√°t hi·ªán c√°c patterns th√∫ v·ªã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bcbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_TOP_HUI and 'df_hui' in dir() and df_hui is not None and not df_hui.empty:\n",
    "    # Plot Top High-Utility Itemsets\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    top_hui = df_hui.head(TOP_N).copy()\n",
    "    colors = sns.color_palette('viridis', len(top_hui))\n",
    "    \n",
    "    bars = ax.barh(\n",
    "        range(len(top_hui)), \n",
    "        top_hui['utility'],\n",
    "        color=colors\n",
    "    )\n",
    "    \n",
    "    ax.set_yticks(range(len(top_hui)))\n",
    "    ax.set_yticklabels(top_hui['itemset_str'], fontsize=9)\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    ax.set_xlabel('Utility (¬£)', fontsize=12)\n",
    "    ax.set_title(f'Top {TOP_N} High-Utility Itemsets', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Th√™m gi√° tr·ªã tr√™n thanh\n",
    "    for i, (bar, utility) in enumerate(zip(bars, top_hui['utility'])):\n",
    "        ax.text(\n",
    "            bar.get_width() + 100, bar.get_y() + bar.get_height()/2,\n",
    "            f'¬£{utility:,.0f}',\n",
    "            va='center', fontsize=9\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # L∆∞u bi·ªÉu ƒë·ªì\n",
    "    chart_path = os.path.join(LAB_OUTPUT_DIR, '6.2 Top High-Utility Itemsets.png')\n",
    "    plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_COMPARISON:\n",
    "    # Scatter plot: Utility vs Frequency\n",
    "    fig = px.scatter(\n",
    "        df_comparison.head(100),\n",
    "        x='frequency_percent',\n",
    "        y='utility_percent',\n",
    "        hover_name='item',\n",
    "        size='utility',\n",
    "        color='utility',\n",
    "        color_continuous_scale='Viridis',\n",
    "        title='So s√°nh Utility vs Frequency c·ªßa c√°c s·∫£n ph·∫©m',\n",
    "        labels={\n",
    "            'frequency_percent': 'Frequency (%)',\n",
    "            'utility_percent': 'Utility (%)',\n",
    "            'utility': 'Utility (¬£)'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=900,\n",
    "        height=600,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    # L∆∞u bi·ªÉu ƒë·ªì\n",
    "    chart_path = os.path.join(LAB_OUTPUT_DIR, '6.2 Utility vs Frequency Scatter.png')\n",
    "    try:\n",
    "        fig.write_image(chart_path)\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "    except Exception as e:\n",
    "        # Fallback: l∆∞u HTML n·∫øu kh√¥ng c√≥ kaleido\n",
    "        html_path = chart_path.replace('.png', '.html')\n",
    "        fig.write_html(html_path)\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì HTML: {html_path}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe72b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT_UTILITY_DISTRIBUTION:\n",
    "    # Ph√¢n ph·ªëi utility theo ƒë·ªô d√†i itemset\n",
    "    if 'df_hui' in dir() and df_hui is not None and not df_hui.empty and 'length' in df_hui.columns:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # S·ªë l∆∞·ª£ng HUI theo ƒë·ªô d√†i\n",
    "        length_counts = df_hui['length'].value_counts().sort_index()\n",
    "        axes[0].bar(length_counts.index, length_counts.values, color='steelblue')\n",
    "        axes[0].set_xlabel('ƒê·ªô d√†i Itemset')\n",
    "        axes[0].set_ylabel('S·ªë l∆∞·ª£ng HUI')\n",
    "        axes[0].set_title('Ph√¢n ph·ªëi High-Utility Itemsets theo ƒë·ªô d√†i')\n",
    "        \n",
    "        # T·ªïng utility theo ƒë·ªô d√†i\n",
    "        utility_by_length = df_hui.groupby('length')['utility'].sum()\n",
    "        axes[1].bar(utility_by_length.index, utility_by_length.values, color='coral')\n",
    "        axes[1].set_xlabel('ƒê·ªô d√†i Itemset')\n",
    "        axes[1].set_ylabel('T·ªïng Utility (¬£)')\n",
    "        axes[1].set_title('T·ªïng Utility theo ƒë·ªô d√†i Itemset')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # L∆∞u bi·ªÉu ƒë·ªì\n",
    "        chart_path = os.path.join(LAB_OUTPUT_DIR, '6.2 Phan Bo HUI theo Do Dai.png')\n",
    "        plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3572b74c",
   "metadata": {},
   "source": [
    "### 6.3 Ph√°t Hi·ªán \"Hidden Gems\"\n",
    "\n",
    "T√¨m c√°c s·∫£n ph·∫©m c√≥ utility cao nh∆∞ng frequency th·∫•p - ƒë√¢y l√† nh·ªØng s·∫£n ph·∫©m c√≥ th·ªÉ b·ªã b·ªè l·ª° n·∫øu ch·ªâ s·ª≠ d·ª•ng Frequent Pattern Mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ce1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√¨m c√°c s·∫£n ph·∫©m c√≥ utility cao nh∆∞ng frequency th·∫•p\n",
    "# ƒê√¢y l√† nh·ªØng \"hidden gems\" m√† Frequent Pattern Mining c√≥ th·ªÉ b·ªè l·ª°\n",
    "\n",
    "median_freq = df_comparison['frequency_percent'].median()\n",
    "median_util = df_comparison['utility_percent'].median()\n",
    "\n",
    "hidden_gems = df_comparison[\n",
    "    (df_comparison['frequency_percent'] < median_freq) &\n",
    "    (df_comparison['utility_percent'] > median_util * 2)\n",
    "].head(20)\n",
    "\n",
    "print(\"=== HIDDEN GEMS: S·∫£n ph·∫©m c√≥ Utility cao nh∆∞ng Frequency th·∫•p ===\")\n",
    "print(\"(Nh·ªØng s·∫£n ph·∫©m n√†y c√≥ th·ªÉ b·ªã b·ªè l·ª° n·∫øu ch·ªâ d√πng Frequent Pattern Mining)\")\n",
    "print()\n",
    "if not hidden_gems.empty:\n",
    "    print(hidden_gems[['item', 'utility', 'utility_percent', 'frequency', 'frequency_percent']].to_string())\n",
    "else:\n",
    "    print(\"Kh√¥ng t√¨m th·∫•y hidden gems v·ªõi ng∆∞·ª°ng hi·ªán t·∫°i.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4abf423",
   "metadata": {},
   "source": [
    "### 6.4 Ph√¢n Lo·∫°i S·∫£n Ph·∫©m\n",
    "\n",
    "Ph√¢n lo·∫°i s·∫£n ph·∫©m theo ma tr·∫≠n Utility-Frequency: Stars, Hidden Gems, Volume Drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bd209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√≠nh support cho c√°c item\n",
    "n_transactions = df[INVOICE_COL].nunique()\n",
    "\n",
    "df_comparison['support'] = df_comparison['frequency'] / n_transactions\n",
    "\n",
    "# Ph√¢n lo·∫°i items\n",
    "df_comparison['category'] = 'Kh√°c'\n",
    "\n",
    "# High Utility, High Frequency\n",
    "df_comparison.loc[\n",
    "    (df_comparison['utility_percent'] > df_comparison['utility_percent'].quantile(0.75)) &\n",
    "    (df_comparison['frequency_percent'] > df_comparison['frequency_percent'].quantile(0.75)),\n",
    "    'category'\n",
    "] = 'Stars (High Utility + High Freq)'\n",
    "\n",
    "# High Utility, Low Frequency\n",
    "df_comparison.loc[\n",
    "    (df_comparison['utility_percent'] > df_comparison['utility_percent'].quantile(0.75)) &\n",
    "    (df_comparison['frequency_percent'] <= df_comparison['frequency_percent'].quantile(0.25)),\n",
    "    'category'\n",
    "] = 'Hidden Gems (High Utility, Low Freq)'\n",
    "\n",
    "# Low Utility, High Frequency\n",
    "df_comparison.loc[\n",
    "    (df_comparison['utility_percent'] <= df_comparison['utility_percent'].quantile(0.25)) &\n",
    "    (df_comparison['frequency_percent'] > df_comparison['frequency_percent'].quantile(0.75)),\n",
    "    'category'\n",
    "] = 'Volume Drivers (Low Utility, High Freq)'\n",
    "\n",
    "print(\"=== Ph√¢n lo·∫°i s·∫£n ph·∫©m ===\")\n",
    "print(df_comparison['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5063223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ph√¢n lo·∫°i\n",
    "fig = px.scatter(\n",
    "    df_comparison,\n",
    "    x='frequency_percent',\n",
    "    y='utility_percent',\n",
    "    color='category',\n",
    "    hover_name='item',\n",
    "    title='Ma tr·∫≠n Utility-Frequency: Ph√¢n lo·∫°i s·∫£n ph·∫©m',\n",
    "    labels={\n",
    "        'frequency_percent': 'Frequency (%)',\n",
    "        'utility_percent': 'Utility (%)',\n",
    "        'category': 'Ph√¢n lo·∫°i'\n",
    "    },\n",
    "    color_discrete_map={\n",
    "        'Stars (High Utility + High Freq)': '#2ecc71',\n",
    "        'Hidden Gems (High Utility, Low Freq)': '#e74c3c',\n",
    "        'Volume Drivers (Low Utility, High Freq)': '#3498db',\n",
    "        'Kh√°c': '#95a5a6'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=700,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "# Th√™m ƒë∆∞·ªùng tham chi·∫øu\n",
    "fig.add_hline(\n",
    "    y=df_comparison['utility_percent'].quantile(0.75),\n",
    "    line_dash=\"dash\", line_color=\"gray\",\n",
    "    annotation_text=\"75th percentile Utility\"\n",
    ")\n",
    "fig.add_vline(\n",
    "    x=df_comparison['frequency_percent'].quantile(0.75),\n",
    "    line_dash=\"dash\", line_color=\"gray\",\n",
    "    annotation_text=\"75th percentile Frequency\"\n",
    ")\n",
    "\n",
    "# L∆∞u bi·ªÉu ƒë·ªì\n",
    "chart_path = os.path.join(LAB_OUTPUT_DIR, '6.4 Ma Tran Utility-Frequency.png')\n",
    "try:\n",
    "    fig.write_image(chart_path)\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "except Exception as e:\n",
    "    # Fallback: l∆∞u HTML n·∫øu kh√¥ng c√≥ kaleido\n",
    "    html_path = chart_path.replace('.png', '.html')\n",
    "    fig.write_html(html_path)\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì HTML: {html_path}\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f60ad",
   "metadata": {},
   "source": [
    "### 6.5 L∆∞u K·∫øt Qu·∫£ Ph√¢n T√≠ch\n",
    "\n",
    "L∆∞u c√°c k·∫øt qu·∫£ ph√¢n t√≠ch v√†o file CSV ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b360a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u High-Utility Itemsets\n",
    "output_path = os.path.join(project_root, HUI_OUTPUT_PATH)\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "if not df_hui.empty:\n",
    "    # Convert frozenset to string for saving\n",
    "    df_hui_save = df_hui.copy()\n",
    "    df_hui_save['itemset'] = df_hui_save['itemset'].apply(lambda x: str(set(x)))\n",
    "    df_hui_save.to_csv(output_path, index=False)\n",
    "    print(f\"ƒê√£ l∆∞u High-Utility Itemsets: {output_path}\")\n",
    "else:\n",
    "    print(\"Kh√¥ng c√≥ High-Utility Itemsets ƒë·ªÉ l∆∞u.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0bb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u th·ªëng k√™ item comparison\n",
    "comparison_path = os.path.join(project_root, OUTPUT_DIR, 'item_utility_frequency_comparison.csv')\n",
    "df_comparison.to_csv(comparison_path, index=False)\n",
    "print(f\"ƒê√£ l∆∞u so s√°nh Utility vs Frequency: {comparison_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d5e3b",
   "metadata": {},
   "source": [
    "## 7. So S√°nh T∆∞ Duy: Frequent Pattern Mining vs High-Utility Mining\n",
    "\n",
    "### 7.1 Kh√°i ni·ªám c·ªët l√µi\n",
    "\n",
    "| Ti√™u ch√≠ | Frequent Pattern Mining (FIM) | High-Utility Itemset Mining (HUIM) |\n",
    "|----------|------------------------------|-----------------------------------|\n",
    "| **M·ª•c ti√™u** | T√¨m items **xu·∫•t hi·ªán nhi·ªÅu** | T√¨m items **gi√° tr·ªã cao** |\n",
    "| **ƒê·ªô ƒëo** | Support = S·ªë l·∫ßn xu·∫•t hi·ªán / T·ªïng giao d·ªãch | Utility = Œ£(Quantity √ó Price) |\n",
    "| **T∆∞ duy** | \"B√°n nhi·ªÅu = Quan tr·ªçng\" | \"L·ª£i nhu·∫≠n cao = Quan tr·ªçng\" |\n",
    "| **∆Øu ƒëi·ªÉm** | Downward Closure Property ‚Üí C·∫Øt t·ªâa hi·ªáu qu·∫£ | Ph·∫£n √°nh ƒë√∫ng gi√° tr·ªã kinh doanh |\n",
    "| **Nh∆∞·ª£c ƒëi·ªÉm** | B·ªè l·ª° items gi√° tr·ªã cao nh∆∞ng √≠t b√°n | Ph·ª©c t·∫°p h∆°n (c·∫ßn TWU bound) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e61ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.0 SETUP ƒê·ªòC L·∫¨P CHO SECTION 7\n",
    "# ============================================================\n",
    "# Cell n√†y cho ph√©p ch·∫°y Section 7 m√† KH√îNG c·∫ßn ch·∫°y l·∫°i to√†n b·ªô notebook\n",
    "# Ch·ªâ c·∫ßn c√≥ file cleaned_uk_data.csv ƒë√£ ƒë∆∞·ª£c t·∫°o tr∆∞·ªõc ƒë√≥\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ==================== PARAMETERS ====================\n",
    "INVOICE_COL = \"InvoiceNo\"\n",
    "ITEM_COL = \"Description\"\n",
    "QUANTITY_COL = \"Quantity\"\n",
    "TOTAL_COL = \"TotalPrice\"\n",
    "\n",
    "# M√†u s·∫Øc\n",
    "COLOR_BLUE = '#3498db'    # Xanh d∆∞∆°ng - cho Frequency/Volume\n",
    "COLOR_GREEN = '#2ecc71'   # Xanh l√° c√¢y - cho Utility/Profit  \n",
    "COLOR_ORANGE = '#e67e22'  # Cam - cho Highlights/Important\n",
    "COLOR_GRAY = '#95a5a6'    # X√°m - cho c√°c m·ª•c kh√°c\n",
    "\n",
    "# ==================== LOAD D·ªÆ LI·ªÜU ====================\n",
    "# T√¨m ƒë∆∞·ªùng d·∫´n project root\n",
    "current_dir = os.getcwd()\n",
    "if 'Lab_PhatTrien_5315' in current_dir:\n",
    "    project_root = current_dir.split('Lab_PhatTrien_5315')[0].rstrip(os.sep)\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu\n",
    "CLEANED_DATA_PATH = os.path.join(project_root, \"data\", \"processed\", \"cleaned_uk_data.csv\")\n",
    "LAB_OUTPUT_DIR = os.path.join(project_root, \"Lab_PhatTrien_5315\", \"output\")\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "os.makedirs(LAB_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load d·ªØ li·ªáu - lu√¥n load l·∫°i ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫•t qu√°n\n",
    "print(\"üìÇ Loading data cho Section 7...\")\n",
    "try:\n",
    "    # Ki·ªÉm tra xem df ƒë√£ t·ªìn t·∫°i v√† h·ª£p l·ªá ch∆∞a\n",
    "    if 'df' in globals() and isinstance(df, pd.DataFrame) and len(df) > 0:\n",
    "        print(f\"‚úÖ S·ª≠ d·ª•ng DataFrame ƒë√£ c√≥ trong memory ({len(df):,} records)\")\n",
    "    else:\n",
    "        raise NameError(\"df not found or invalid\")\n",
    "except (NameError, TypeError):\n",
    "    df = pd.read_csv(CLEANED_DATA_PATH)\n",
    "    print(f\"‚úÖ Loaded {len(df):,} records t·ª´ {CLEANED_DATA_PATH}\")\n",
    "\n",
    "# T√≠nh TOTAL_UTILITY - lu√¥n t√≠nh l·∫°i t·ª´ df ƒë·ªÉ ƒë·∫£m b·∫£o ch√≠nh x√°c\n",
    "TOTAL_UTILITY = df[TOTAL_COL].sum()\n",
    "print(f\"‚úÖ TOTAL_UTILITY = ¬£{TOTAL_UTILITY:,.2f}\")\n",
    "\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"   - S·ªë d√≤ng: {len(df):,}\")\n",
    "print(f\"   - S·ªë invoices: {df[INVOICE_COL].nunique():,}\")\n",
    "print(f\"   - S·ªë items: {df[ITEM_COL].nunique():,}\")\n",
    "print(f\"   - Total Utility: ¬£{TOTAL_UTILITY:,.2f}\")\n",
    "print(\"\\n‚úÖ Section 7 s·∫µn s√†ng ch·∫°y!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7.2 SO S√ÅNH TR·ª∞C TI·∫æP: TOP ITEMS THEO FREQUENCY VS UTILITY\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä SO S√ÅNH T∆Ø DUY: FREQUENT vs HIGH-UTILITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# T√≠nh Frequency cho m·ªói item (s·ªë l·∫ßn xu·∫•t hi·ªán trong c√°c invoice)\n",
    "item_frequency = df.groupby(ITEM_COL).agg({\n",
    "    INVOICE_COL: 'nunique',      # S·ªë invoice ch·ª©a item\n",
    "    QUANTITY_COL: 'sum',         # T·ªïng quantity\n",
    "    TOTAL_COL: 'sum'             # T·ªïng utility\n",
    "}).reset_index()\n",
    "\n",
    "item_frequency.columns = ['item', 'frequency', 'total_quantity', 'total_utility']\n",
    "\n",
    "# T√≠nh support % \n",
    "total_invoices = df[INVOICE_COL].nunique()\n",
    "item_frequency['support_percent'] = item_frequency['frequency'] / total_invoices * 100\n",
    "item_frequency['utility_percent'] = item_frequency['total_utility'] / TOTAL_UTILITY * 100\n",
    "\n",
    "# S·∫Øp x·∫øp theo frequency v√† utility\n",
    "top_by_frequency = item_frequency.nlargest(20, 'frequency').copy()\n",
    "top_by_utility = item_frequency.nlargest(20, 'total_utility').copy()\n",
    "\n",
    "print(f\"\\nüìà T·ªïng s·ªë items: {len(item_frequency):,}\")\n",
    "print(f\"üìà T·ªïng s·ªë invoices: {total_invoices:,}\")\n",
    "print(f\"üìà T·ªïng utility: ¬£{TOTAL_UTILITY:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hi·ªÉn th·ªã Top 10 theo Frequency\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîµ TOP 10 ITEMS THEO FREQUENCY (T∆∞ duy Frequent Pattern Mining)\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚Üí ƒê√¢y l√† nh·ªØng items s·∫Ω ƒë∆∞·ª£c FIM ∆∞u ti√™n t√¨m ra\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for rank, (_, row) in enumerate(top_by_frequency.head(10).iterrows(), 1):\n",
    "    print(f\"{rank:2}. {row['item'][:50]:<50}\")\n",
    "    print(f\"    Frequency: {row['frequency']:,} invoices ({row['support_percent']:.2f}%)\")\n",
    "    print(f\"    Utility: ¬£{row['total_utility']:,.2f} ({row['utility_percent']:.4f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31d74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hi·ªÉn th·ªã Top 10 theo Utility\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üü¢ TOP 10 ITEMS THEO UTILITY (T∆∞ duy High-Utility Mining)\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚Üí ƒê√¢y l√† nh·ªØng items s·∫Ω ƒë∆∞·ª£c HUIM ∆∞u ti√™n t√¨m ra\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for rank, (_, row) in enumerate(top_by_utility.head(10).iterrows(), 1):\n",
    "    print(f\"{rank:2}. {row['item'][:50]:<50}\")\n",
    "    print(f\"    Utility: ¬£{row['total_utility']:,.2f} ({row['utility_percent']:.4f}%)\")\n",
    "    print(f\"    Frequency: {row['frequency']:,} invoices ({row['support_percent']:.2f}%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf120df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch s·ª± kh√°c bi·ªát gi·ªØa 2 t·∫≠p top items\n",
    "top_freq_items = set(top_by_frequency.head(10)['item'])\n",
    "top_util_items = set(top_by_utility.head(10)['item'])\n",
    "\n",
    "common_items = top_freq_items & top_util_items\n",
    "only_in_freq = top_freq_items - top_util_items  # \"Volume Drivers\"\n",
    "only_in_util = top_util_items - top_freq_items  # \"Hidden Gems\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç PH√ÇN T√çCH S·ª∞ KH√ÅC BI·ªÜT GI·ªÆA HAI T∆Ø DUY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n‚≠ê STARS (C·∫£ 2 ƒë·ªÅu ch·ªçn): {len(common_items)} items\")\n",
    "print(\"-\"*40)\n",
    "for item in common_items:\n",
    "    row = item_frequency[item_frequency['item'] == item].iloc[0]\n",
    "    print(f\"  ‚Ä¢ {item[:45]}\")\n",
    "    print(f\"    Freq: {row['frequency']:,} | Utility: ¬£{row['total_utility']:,.0f}\")\n",
    "\n",
    "print(f\"\\nüîµ VOLUME DRIVERS (Ch·ªâ FIM ch·ªçn - b√°n nhi·ªÅu, l·ªùi √≠t): {len(only_in_freq)} items\")\n",
    "print(\"-\"*40)\n",
    "for item in only_in_freq:\n",
    "    row = item_frequency[item_frequency['item'] == item].iloc[0]\n",
    "    print(f\"  ‚Ä¢ {item[:45]}\")\n",
    "    print(f\"    Freq: {row['frequency']:,} | Utility: ¬£{row['total_utility']:,.0f}\")\n",
    "\n",
    "print(f\"\\nüíé HIDDEN GEMS (Ch·ªâ HUIM ch·ªçn - b√°n √≠t, l·ªùi nhi·ªÅu): {len(only_in_util)} items\")\n",
    "print(\"-\"*40)\n",
    "for item in only_in_util:\n",
    "    row = item_frequency[item_frequency['item'] == item].iloc[0]\n",
    "    print(f\"  ‚Ä¢ {item[:45]}\")\n",
    "    print(f\"    Freq: {row['frequency']:,} | Utility: ¬£{row['total_utility']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: So s√°nh tr·ª±c quan\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# 1. Bar chart so s√°nh Top 10 Frequency vs Utility\n",
    "ax1 = axes[0, 0]\n",
    "top10_freq = top_by_frequency.head(10).copy()\n",
    "top10_freq['short_name'] = top10_freq['item'].str[:25] + '...'\n",
    "colors = [COLOR_GREEN if item in top_util_items else COLOR_BLUE for item in top10_freq['item']]\n",
    "bars = ax1.barh(range(len(top10_freq)), top10_freq['frequency'], color=colors, alpha=0.8)\n",
    "ax1.set_yticks(range(len(top10_freq)))\n",
    "ax1.set_yticklabels(top10_freq['short_name'], fontsize=9)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlabel('Frequency (s·ªë invoices)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Top 10 theo FREQUENCY\\n(Xanh l√° = c≈©ng n·∫±m trong Top Utility)', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Bar chart Top 10 Utility\n",
    "ax2 = axes[0, 1]\n",
    "top10_util = top_by_utility.head(10).copy()\n",
    "top10_util['short_name'] = top10_util['item'].str[:25] + '...'\n",
    "colors = [COLOR_BLUE if item in top_freq_items else COLOR_GREEN for item in top10_util['item']]\n",
    "bars = ax2.barh(range(len(top10_util)), top10_util['total_utility'], color=colors, alpha=0.8)\n",
    "ax2.set_yticks(range(len(top10_util)))\n",
    "ax2.set_yticklabels(top10_util['short_name'], fontsize=9)\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_xlabel('Utility (¬£)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Top 10 theo UTILITY\\n(Xanh d∆∞∆°ng = c≈©ng n·∫±m trong Top Frequency)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Scatter plot: Frequency vs Utility v·ªõi ph√¢n lo·∫°i\n",
    "ax3 = axes[1, 0]\n",
    "\n",
    "# Ph√¢n lo·∫°i items\n",
    "item_frequency['category'] = 'Others'\n",
    "item_frequency.loc[item_frequency['item'].isin(common_items), 'category'] = 'Stars'\n",
    "item_frequency.loc[item_frequency['item'].isin(only_in_freq), 'category'] = 'Volume Drivers'\n",
    "item_frequency.loc[item_frequency['item'].isin(only_in_util), 'category'] = 'Hidden Gems'\n",
    "\n",
    "category_colors = {'Stars': COLOR_ORANGE, 'Volume Drivers': COLOR_BLUE, \n",
    "                   'Hidden Gems': COLOR_GREEN, 'Others': COLOR_GRAY}\n",
    "\n",
    "for cat in ['Others', 'Volume Drivers', 'Hidden Gems', 'Stars']:\n",
    "    subset = item_frequency[item_frequency['category'] == cat]\n",
    "    alpha = 0.3 if cat == 'Others' else 0.8\n",
    "    size = 30 if cat == 'Others' else 150\n",
    "    ax3.scatter(subset['frequency'], subset['total_utility'], \n",
    "                c=category_colors[cat], label=cat, alpha=alpha, s=size, edgecolors='white')\n",
    "\n",
    "ax3.set_xlabel('Frequency (s·ªë invoices)', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Utility (¬£)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Frequency vs Utility - Ph√¢n Lo·∫°i Items', fontsize=12, fontweight='bold')\n",
    "ax3.legend(fontsize=10, loc='upper right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "# 4. Venn-style comparison\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "# T·∫°o summary text\n",
    "summary_text = f\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë           SO S√ÅNH T∆Ø DUY: FIM vs HUIM                           ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  üîµ Frequent Pattern Mining (FIM)                               ‚ïë\n",
    "‚ïë     ‚Ä¢ M·ª•c ti√™u: T√¨m items XU·∫§T HI·ªÜN NHI·ªÄU                       ‚ïë\n",
    "‚ïë     ‚Ä¢ Metric: Support = Frequency / Total Transactions          ‚ïë\n",
    "‚ïë     ‚Ä¢ K·∫øt qu·∫£: {len(top_freq_items)} items trong Top 10                            ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  üü¢ High-Utility Itemset Mining (HUIM)                          ‚ïë\n",
    "‚ïë     ‚Ä¢ M·ª•c ti√™u: T√¨m items GI√Å TR·ªä CAO                           ‚ïë\n",
    "‚ïë     ‚Ä¢ Metric: Utility = Quantity √ó Price                        ‚ïë\n",
    "‚ïë     ‚Ä¢ K·∫øt qu·∫£: {len(top_util_items)} items trong Top 10                            ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë  ‚≠ê STARS (c·∫£ 2 ch·ªçn):        {len(common_items):2} items                            ‚ïë\n",
    "‚ïë  üîµ VOLUME DRIVERS (FIM):     {len(only_in_freq):2} items (b√°n nhi·ªÅu, l·ªùi √≠t)       ‚ïë\n",
    "‚ïë  üíé HIDDEN GEMS (HUIM):       {len(only_in_util):2} items (b√°n √≠t, l·ªùi nhi·ªÅu)       ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïë  üí° K·∫æT LU·∫¨N:                                                   ‚ïë\n",
    "‚ïë  ‚Ä¢ FIM b·ªè l·ª° {len(only_in_util)} \"Hidden Gems\" - items gi√° tr·ªã cao               ‚ïë\n",
    "‚ïë  ‚Ä¢ HUIM b·ªè qua {len(only_in_freq)} \"Volume Drivers\" - items b√°n ch·∫°y             ‚ïë\n",
    "‚ïë  ‚Ä¢ C·∫ßn K·∫æT H·ª¢P c·∫£ hai ƒë·ªÉ c√≥ chi·∫øn l∆∞·ª£c to√†n di·ªán!               ‚ïë\n",
    "‚ïë                                                                  ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.5, 0.5, summary_text, transform=ax4.transAxes, fontsize=10,\n",
    "         verticalalignment='center', horizontalalignment='center',\n",
    "         fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# L∆∞u bi·ªÉu ƒë·ªì\n",
    "chart_path = os.path.join(LAB_OUTPUT_DIR, '7.2 So Sanh FIM vs HUIM.png')\n",
    "plt.savefig(chart_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì: {chart_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B·∫£ng so s√°nh chi ti·∫øt v·ªõi v√≠ d·ª• c·ª• th·ªÉ\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã V√ç D·ª§ C·ª§ TH·ªÇ: T·∫†I SAO HAI T∆Ø DUY KH√ÅC NHAU?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# T√¨m m·ªôt Hidden Gem ƒëi·ªÉn h√¨nh\n",
    "if only_in_util:\n",
    "    hidden_gem = list(only_in_util)[0]\n",
    "    hg_data = item_frequency[item_frequency['item'] == hidden_gem].iloc[0]\n",
    "    \n",
    "    print(f\"\\nüíé HIDDEN GEM: '{hidden_gem[:50]}'\")\n",
    "    print(f\"   ‚Ä¢ Frequency: {hg_data['frequency']:,} invoices ({hg_data['support_percent']:.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ Utility: ¬£{hg_data['total_utility']:,.2f} ({hg_data['utility_percent']:.4f}%)\")\n",
    "    print(f\"   ‚Üí FIM s·∫Ω B·ªé QUA item n√†y v√¨ support th·∫•p!\")\n",
    "    print(f\"   ‚Üí HUIM s·∫Ω T√åM RA item n√†y v√¨ utility cao!\")\n",
    "\n",
    "# T√¨m m·ªôt Volume Driver ƒëi·ªÉn h√¨nh\n",
    "if only_in_freq:\n",
    "    vol_driver = list(only_in_freq)[0]\n",
    "    vd_data = item_frequency[item_frequency['item'] == vol_driver].iloc[0]\n",
    "    \n",
    "    print(f\"\\nüîµ VOLUME DRIVER: '{vol_driver[:50]}'\")\n",
    "    print(f\"   ‚Ä¢ Frequency: {vd_data['frequency']:,} invoices ({vd_data['support_percent']:.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ Utility: ¬£{vd_data['total_utility']:,.2f} ({vd_data['utility_percent']:.4f}%)\")\n",
    "    print(f\"   ‚Üí FIM s·∫Ω T√åM RA item n√†y v√¨ support cao!\")\n",
    "    print(f\"   ‚Üí HUIM c√≥ th·ªÉ B·ªé QUA n·∫øu ng∆∞·ª°ng utility cao!\")\n",
    "\n",
    "# T√¨m m·ªôt Star\n",
    "if common_items:\n",
    "    star = list(common_items)[0]\n",
    "    star_data = item_frequency[item_frequency['item'] == star].iloc[0]\n",
    "    \n",
    "    print(f\"\\n‚≠ê STAR: '{star[:50]}'\")\n",
    "    print(f\"   ‚Ä¢ Frequency: {star_data['frequency']:,} invoices ({star_data['support_percent']:.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ Utility: ¬£{star_data['total_utility']:,.2f} ({star_data['utility_percent']:.4f}%)\")\n",
    "    print(f\"   ‚Üí C·∫¢ HAI ƒë·ªÅu t√¨m ra item n√†y!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° K·∫æT LU·∫¨N V·ªÄ S·ª∞ KH√ÅC BI·ªÜT T∆Ø DUY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ FREQUENT PATTERN MINING (FIM)                                          ‚îÇ\n",
    "‚îÇ ‚Ä¢ T∆∞ duy: \"Items b√°n NHI·ªÄU l√† quan tr·ªçng\"                              ‚îÇ\n",
    "‚îÇ ‚Ä¢ ∆Øu ƒëi·ªÉm: T√¨m patterns ph·ªï bi·∫øn, t·ªët cho cross-selling               ‚îÇ\n",
    "‚îÇ ‚Ä¢ Nh∆∞·ª£c ƒëi·ªÉm: B·ªè l·ª° items gi√° tr·ªã cao nh∆∞ng √≠t ph·ªï bi·∫øn               ‚îÇ\n",
    "‚îÇ ‚Ä¢ ·ª®ng d·ª•ng: G·ª£i √Ω s·∫£n ph·∫©m, ph√¢n t√≠ch h√†nh vi mua h√†ng               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ HIGH-UTILITY ITEMSET MINING (HUIM)                                     ‚îÇ\n",
    "‚îÇ ‚Ä¢ T∆∞ duy: \"Items c√≥ GI√Å TR·ªä CAO l√† quan tr·ªçng\"                        ‚îÇ\n",
    "‚îÇ ‚Ä¢ ∆Øu ƒëi·ªÉm: Ph·∫£n √°nh ƒë√∫ng gi√° tr·ªã kinh doanh th·ª±c s·ª±                   ‚îÇ\n",
    "‚îÇ ‚Ä¢ Nh∆∞·ª£c ƒëi·ªÉm: C√≥ th·ªÉ b·ªè qua items b√°n ch·∫°y nh∆∞ng margin th·∫•p          ‚îÇ\n",
    "‚îÇ ‚Ä¢ ·ª®ng d·ª•ng: T·ªëi ∆∞u doanh thu, t√¨m s·∫£n ph·∫©m l·ª£i nhu·∫≠n cao             ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ KHUY·∫æN NGH·ªä: K·∫øt h·ª£p C·∫¢ HAI ƒë·ªÉ c√≥ chi·∫øn l∆∞·ª£c to√†n di·ªán!               ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u b·∫£ng so s√°nh chi ti·∫øt\n",
    "comparison_df = item_frequency[['item', 'frequency', 'support_percent', \n",
    "                                 'total_utility', 'utility_percent', 'category']].copy()\n",
    "comparison_df = comparison_df.sort_values('total_utility', ascending=False)\n",
    "\n",
    "# Th√™m ranking\n",
    "comparison_df['rank_by_frequency'] = comparison_df['frequency'].rank(ascending=False).astype(int)\n",
    "comparison_df['rank_by_utility'] = comparison_df['total_utility'].rank(ascending=False).astype(int)\n",
    "comparison_df['rank_difference'] = comparison_df['rank_by_frequency'] - comparison_df['rank_by_utility']\n",
    "\n",
    "# L∆∞u file\n",
    "comparison_output_path = os.path.join(LAB_OUTPUT_DIR, 'SoSanh_FIM_vs_HUIM.csv')\n",
    "comparison_df.to_csv(comparison_output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u b·∫£ng so s√°nh: {comparison_output_path}\")\n",
    "\n",
    "# Hi·ªÉn th·ªã c√°c items c√≥ s·ª± kh√°c bi·ªát l·ªõn nh·∫•t\n",
    "print(\"\\nüìä TOP 10 ITEMS C√ì S·ª∞ KH√ÅC BI·ªÜT L·ªöN NH·∫§T GI·ªÆA RANKING:\")\n",
    "print(\"-\"*80)\n",
    "extreme_diff = comparison_df.nlargest(10, 'rank_difference', keep='first')\n",
    "for _, row in extreme_diff.iterrows():\n",
    "    print(f\"‚Ä¢ {row['item'][:45]}\")\n",
    "    print(f\"  Rank Freq: #{int(row['rank_by_frequency'])} | Rank Util: #{int(row['rank_by_utility'])} | Diff: {int(row['rank_difference'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec43aa7",
   "metadata": {},
   "source": [
    "### 7.4 ƒê·ªÅ xu·∫•t Kinh Doanh\n",
    "\n",
    "D·ª±a tr√™n k·∫øt qu·∫£ ph√¢n lo·∫°i items:\n",
    "\n",
    "1. **Hidden Gems**: C√°c s·∫£n ph·∫©m c√≥ utility cao nh∆∞ng frequency th·∫•p - ƒë√¢y l√† nh·ªØng s·∫£n ph·∫©m c√≥ th·ªÉ b·ªã b·ªè l·ª° n·∫øu ch·ªâ d√πng Frequent Pattern Mining.\n",
    "\n",
    "2. **Volume Drivers**: C√°c s·∫£n ph·∫©m b√°n ch·∫°y nh∆∞ng margin th·∫•p - quan tr·ªçng ƒë·ªÉ duy tr√¨ traffic nh∆∞ng kh√¥ng ph·∫£i ngu·ªìn l·ª£i nhu·∫≠n ch√≠nh.\n",
    "\n",
    "3. **Stars**: S·∫£n ph·∫©m v·ª´a b√°n ch·∫°y v·ª´a sinh l·ªùi cao - c·∫ßn ∆∞u ti√™n qu·∫£ng b√° v√† ƒë·∫£m b·∫£o inventory.\n",
    "\n",
    "**Chi·∫øn l∆∞·ª£c:**\n",
    "\n",
    "- **V·ªõi Hidden Gems**: TƒÉng visibility, marketing ƒë·ªÉ chuy·ªÉn th√†nh Stars\n",
    "- **V·ªõi Volume Drivers**: S·ª≠ d·ª•ng l√†m s·∫£n ph·∫©m \"loss leader\" ƒë·ªÉ thu h√∫t kh√°ch\n",
    "- **V·ªõi Stars**: ƒê·∫£m b·∫£o inventory, t·∫°o bundle deals\n",
    "- **Cross-selling**: K·∫øt h·ª£p High-Utility Itemsets ƒë·ªÉ g·ª£i √Ω s·∫£n ph·∫©m t·ªëi ∆∞u doanh thu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c34b4b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## T√†i li·ªáu tham kh·∫£o\n",
    "\n",
    "1. Liu, Y., Liao, W., & Choudhary, A. (2005). A two-phase algorithm for fast discovery of high utility itemsets. *PAKDD 2005*.\n",
    "\n",
    "2. Fournier-Viger, P., et al. (2014). FHM: Faster high-utility itemset mining using estimated utility co-occurrence pruning. *ISMIS 2014*.\n",
    "\n",
    "3. Gan, W., et al. (2021). A survey of utility-oriented pattern mining. *IEEE Transactions on Knowledge and Data Engineering*.\n",
    "\n",
    "4. Th∆∞ vi·ªán SPMF: http://www.philippe-fournier-viger.com/spmf/ (Java library for pattern mining)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
